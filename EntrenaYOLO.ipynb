{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0459bfbe-4b77-483c-979f-1c8ec8e01f5c",
   "metadata": {},
   "source": [
    "<h1>Entrenar YOLOv8</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176dcf3d-0cf5-4146-b10d-299fb8cd0d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.10 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.5 ðŸš€ Python-3.8.18 torch-2.1.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24214MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/home/jair/COVID/rsna/yolo_train_data/rsna640opacity_sano.yml, epochs=350, time=None, patience=50, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.001, momentum=0.001, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.001, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=autoaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8719894  ultralytics.nn.modules.head.Detect           [2, [320, 640, 640]]          \n",
      "Model summary: 365 layers, 68154534 parameters, 68154518 gradients, 258.1 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 3090 Ti) 23.65G total, 0.58G reserved, 0.56G allocated, 22.51G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    68154534       258.1         1.619         43.38         109.9        (1, 3, 640, 640)                    list\n",
      "    68154534       516.3         2.187            29          60.5        (2, 3, 640, 640)                    list\n",
      "    68154534        1033         3.542         35.25         63.88        (4, 3, 640, 640)                    list\n",
      "    68154534        2065         6.434         61.14         83.62        (8, 3, 640, 640)                    list\n",
      "    68154534        4130        12.369         119.1         152.7       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 17 for CUDA:0 14.16G/23.65G (60%) âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jair/COVID/rsna/datasets/rsna640opacity/labels/train.cache\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jair/COVID/rsna/datasets/rsna640opacity/labels/validation.ca\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.001) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00053125), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/350      14.1G      0.808      1.283      1.393         45        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.378      0.576      0.481      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/350      14.3G      0.753      1.098      1.352         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.929      0.421      0.493      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/350      14.7G      0.694       1.01      1.305         51        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.91      0.464      0.539      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/350      14.7G     0.6513     0.9357      1.269         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.635      0.615      0.636      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/350      14.7G     0.6279     0.8906      1.248         42        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.49      0.666      0.616      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/350      14.7G     0.6009     0.8461      1.227         60        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.606      0.689       0.68      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/350      14.7G      0.596       0.84      1.223         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.686      0.717      0.742      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/350      14.7G       0.57     0.7937      1.204         63        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.646      0.697      0.695      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/350      14.7G     0.5582     0.7808      1.195         45        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.617      0.675       0.68      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/350      14.7G     0.5519     0.7757      1.194         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.652      0.704      0.715      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/350      14.7G     0.5482     0.7698      1.193         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.732      0.754      0.767      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/350      14.7G     0.5372     0.7482      1.184         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.633      0.673      0.685      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/350      14.7G     0.5352     0.7473      1.185         51        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.71      0.732      0.752      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/350      14.7G     0.5243     0.7275      1.182         58        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.628      0.678      0.712      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/350      14.7G     0.5174     0.7152      1.175         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.787      0.749      0.784      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/350      14.7G     0.5231     0.7336       1.18         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.692      0.743      0.757      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/350      14.7G     0.5163      0.714      1.177         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.737      0.749      0.765      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/350      14.7G     0.5025     0.6933      1.167         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.723      0.751       0.76      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/350      14.7G     0.5032      0.697      1.169         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.76      0.757      0.793      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/350      14.7G     0.5118     0.7065      1.176         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.732      0.735      0.759      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/350      14.7G     0.5046      0.694      1.169         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.71      0.746      0.756      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/350      14.7G     0.5051     0.6964      1.169         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.724       0.74      0.767      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/350      14.7G      0.496     0.6865      1.167         52        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.728       0.74      0.761      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/350      14.7G     0.5027     0.6899       1.17         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.758      0.749       0.78      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/350      14.7G     0.4997     0.6742      1.166         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.743      0.748      0.776      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/350      14.7G     0.4998     0.6808       1.17         45        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.773      0.759      0.791      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/350      14.7G     0.4908     0.6745      1.164         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.774       0.77        0.8      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/350      14.7G     0.4915     0.6641      1.161         56        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.776      0.759      0.793      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/350      14.7G     0.4888     0.6638       1.16         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.762      0.771       0.79      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/350      14.7G     0.4879     0.6628       1.16         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.749      0.762      0.776       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/350      14.7G     0.4839     0.6501       1.16         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.735      0.749      0.772      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/350      14.7G     0.4794     0.6502      1.158         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.745      0.757      0.775      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/350      14.7G     0.4872     0.6589      1.162         45        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.786      0.774      0.802       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/350      14.7G     0.4841     0.6506      1.161         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.781      0.762      0.797      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/350      14.7G     0.4783     0.6394      1.155         58        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.776      0.755      0.791      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/350      14.7G     0.4775      0.636      1.156         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.765      0.756      0.786      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/350      14.7G     0.4788     0.6338      1.158         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.759      0.764      0.787      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/350      14.7G     0.4818     0.6414       1.16         52        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.768      0.764      0.796      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/350      14.7G     0.4719     0.6244      1.153         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.781      0.772      0.805       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/350      14.7G      0.477     0.6264      1.157         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.775      0.771        0.8      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/350      14.7G     0.4654     0.6183      1.148         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.78      0.777      0.806      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/350      14.7G     0.4641     0.6123      1.149         51        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.773       0.76      0.793      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/350      14.7G     0.4655     0.6179      1.152         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.783      0.773      0.802      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/350      14.7G     0.4731     0.6229      1.158         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.783      0.777      0.804      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/350      14.7G      0.468     0.6179      1.152         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.764      0.766      0.788      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/350      14.7G      0.466     0.6082       1.15         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.766      0.772      0.796      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/350      14.7G      0.471     0.6086      1.153         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.764       0.77      0.793      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/350      14.7G     0.4574     0.5966      1.145         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.787      0.773      0.803       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/350      14.7G     0.4553     0.5908      1.143         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.783      0.769      0.795      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/350      14.7G     0.4675     0.6019      1.151         42        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.779      0.778      0.802       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/350      14.7G     0.4589     0.5912      1.144         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.783      0.766      0.799      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/350      14.7G     0.4559     0.5838      1.145         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.786      0.769      0.797      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/350      14.7G        inf     0.5836      1.149         52        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.778      0.781      0.796      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/350      14.7G     0.4559     0.5799      1.145         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.774      0.775      0.792      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/350      14.7G     0.4602     0.5778      1.149         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.782      0.778      0.796      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/350      14.7G     0.4556     0.5731      1.143         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.782      0.785      0.798      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/350      14.7G     0.4501     0.5663       1.14         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.786      0.784      0.802      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/350      14.7G      0.458     0.5768      1.144         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.78      0.784      0.798      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/350      14.7G     0.4467     0.5607      1.141         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.782      0.788        0.8      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/350      14.7G     0.4513     0.5622      1.141         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.79      0.787      0.802      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/350      14.7G     0.4491     0.5462       1.14         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.783      0.786      0.799      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/350      14.7G     0.4435      0.545      1.138         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.784      0.784      0.795      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/350      14.7G     0.4544     0.5495      1.141         52        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.786      0.788      0.794      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/350      14.7G     0.4448     0.5411      1.137         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.777      0.789      0.794      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/350      14.7G     0.4436     0.5329      1.138         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.782      0.787      0.795      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/350      14.7G     0.4373       0.52       1.13         51        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.77      0.791       0.79      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/350      14.7G     0.4423      0.537      1.134         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.772      0.783      0.788      0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/350      14.7G     0.4369     0.5227       1.13         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.77      0.787      0.785      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/350      14.7G     0.4438     0.5214       1.13         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.767      0.788      0.784      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/350      14.7G     0.4376     0.5156       1.13         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744       0.78      0.777      0.784      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/350      14.7G     0.4321     0.5078      1.126         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.776       0.78      0.784      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/350      14.7G        inf      0.514      1.129         62        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.774      0.781      0.783       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/350      14.7G     0.4326     0.4951      1.124         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.775      0.785      0.785      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/350      14.7G     0.4329      0.498      1.125         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.771      0.789      0.781       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/350      14.7G     0.4277     0.4894      1.117         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.771      0.785       0.78       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/350      14.7G     0.4258     0.4845      1.117         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.772      0.787       0.78      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/350      14.7G     0.4224     0.4775      1.116         51        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.773      0.785       0.78      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/350      14.7G     0.4286     0.4817      1.119         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.781      0.778      0.779      0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/350      14.7G     0.4233      0.481      1.113         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.782      0.776      0.777      0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/350      14.7G     0.4198     0.4672       1.11         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.772      0.781      0.778      0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/350      14.7G     0.4165     0.4647      1.108         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.774      0.777       0.78      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/350      14.7G     0.4164      0.464      1.106         42        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.767      0.787      0.781      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/350      14.7G     0.4145     0.4573      1.108         52        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.771      0.786      0.777      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/350      14.7G     0.4153     0.4539      1.105         42        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.768      0.789      0.777      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/350      14.7G     0.4156     0.4504      1.104         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.771      0.785      0.774      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/350      14.7G     0.4085     0.4494      1.102         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.774       0.78      0.774      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/350      14.7G     0.4055     0.4422      1.101         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.769      0.784      0.773      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/350      14.7G     0.4086     0.4372      1.101         52        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.772      0.783      0.774      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/350      14.7G     0.4094     0.4366        1.1         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.771      0.787      0.776      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/350      14.7G     0.3984     0.4292      1.092         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.776      0.781      0.775      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/350      14.7G     0.4005     0.4308      1.092         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.771      0.783      0.774      0.601\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 50 epochs. Best results observed at epoch 41, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "91 epochs completed in 7.554 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.5 ðŸš€ Python-3.8.18 torch-2.1.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24214MiB)\n",
      "Model summary (fused): 268 layers, 68125494 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2972       3744      0.771      0.777      0.803      0.636\n",
      "               Opacity       2972       1974      0.639      0.567      0.623      0.288\n",
      "             NoOpacity       2972       1770      0.903      0.986      0.984      0.984\n",
      "Speed: 0.1ms preprocess, 16.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n",
    "#cos_lr=False\n",
    "#augment=False\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "yolon='yolov8n.pt'\n",
    "yolos='yolov8s.pt'\n",
    "yolom='yolov8m.pt'\n",
    "yolol='yolov8l.pt'\n",
    "yolox='yolov8x.pt'\n",
    "yolopretrain='/home/jair/entrenamientos/n/train/weights/best.pt'\n",
    "\n",
    "# Carga modelo con pesos que le pasamos\n",
    "model = YOLO(yolox)  \n",
    "\n",
    "rsna640=\"/home/jair/COVID/rsna/yolo_train_data/rsna640opacity.yml\"\n",
    "rsna640C=\"/home/jair/COVID/rsna/yolo_train_data/rsna640opacity_sano.yml\"\n",
    "rsna1024=\"/home/jair/COVID/rsna/yolo_train_data/rsna1024.yml\"\n",
    "Xray14=\"/home/jair/COVID/NIHX14/datasets/yolo/ChestXray14.yml\"\n",
    "siimcovid=\"/home/jair/COVID/siimcovid/datasets/yolo/SIIMCovid.yml\"\n",
    "\n",
    "\n",
    "#Entrenando el modelo\n",
    "results=model.train(data=rsna640C, epochs=350, imgsz=640, device=0,patience=50,plots=True,batch=-1,optimizer='AdamW',cos_lr=False,augment=True,auto_augment='autoaugment',momentum=0.001,warmup_momentum=0.001,lr0=0.001,lrf=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71facece-e46a-40b6-8fdd-8305d00171b5",
   "metadata": {},
   "source": [
    "<h3>Generar matrices de confusiÃ³n para imÃ¡genes con recuadros delimitadores para opacidades y sin anotaciones para imÃ¡genes sin opacidades</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f6a68-f49f-4603-9175-02b814a136f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generar conteo reinterpretado de matrices de confusion\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mode='validation'\n",
    "model = YOLO('/home/jair/COVID/YOLO8/runs/detect/train/weights/best.pt')\n",
    "Sanos=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+\"_sanos.csv\")\n",
    "S=list(Sanos['rutas'])\n",
    "fallos_s=0\n",
    "for ruta in tqdm(S):\n",
    "    rutam=ruta.replace('rsna640','rsna640opacity')\n",
    "    results=model(rutam,verbose=False)\n",
    "    \n",
    "    for r in results:\n",
    "        if len(r.boxes.xywh.tolist())!=0:\n",
    "            fallos_s=fallos_s+1\n",
    "TS=len(S)\n",
    "\n",
    "\n",
    "model = YOLO('/home/jair/COVID/YOLO8/runs/detect/train/weights/best.pt')\n",
    "Opacity=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+\"_opacity.csv\")\n",
    "O=list(Opacity['rutas'])\n",
    "fallos_o=0\n",
    "for ruta in tqdm(O):\n",
    "    rutam=ruta.replace('rsna640','rsna640opacity')\n",
    "    results=model(rutam,verbose=False)\n",
    "    for r in results:\n",
    "        if len(r.boxes.xywh.tolist())==0:\n",
    "            fallos_o=fallos_o+1\n",
    "TO=len(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419dfed-f326-496a-97d8-f3cdd3a85767",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "VP = TO-fallos_o\n",
    "FP = fallos_o\n",
    "FN = fallos_s\n",
    "VN = TS-fallos_s\n",
    "\n",
    "# Crear la matriz de confusiÃ³n\n",
    "matriz_confusion = [[VP, FP],\n",
    "                    [FN, VN]]\n",
    "\n",
    "# Etiquetas para las clases\n",
    "clases = ['Opacidad', 'Sanos']\n",
    "\n",
    "# ConfiguraciÃ³n del heatmap con Seaborn\n",
    "sns.set(font_scale=1.2)  # Ajusta el tamaÃ±o de la fuente\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Crear el heatmap con etiquetas personalizadas\n",
    "sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\", annot_kws={\"size\": 16},xticklabels=clases, yticklabels=clases)\n",
    "\n",
    "# ConfiguraciÃ³n adicional\n",
    "plt.xlabel('PredicciÃ³n')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.savefig('/home/jair/COVID/YOLO8/runs/detect/train/'+mode+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbab1d7-3689-4a0e-bb0c-0461eb72aede",
   "metadata": {},
   "source": [
    "<h3>Generar matrices de confusiÃ³n para imÃ¡genes con recuadros delimitadores para opacidades y recuadros que encierran cada pulmÃ³n para imÃ¡genes sin presenca de opacidades.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10726e7-b5cc-4955-aa1f-3f20a6399ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96ba93-31cb-4ebc-b836-f191b1a4f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generemos las matrices por detecciÃ³n en imagen\n",
    "#(cuenta por recuadro cuantos son opacidades cuantos sanos y cuantos predicen bien)\n",
    "mode='validation'\n",
    "san=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+'_sanos.csv')\n",
    "opa=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+'_opacity.csv')\n",
    "todas=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/class_opacity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1665ff-3df2-4062-b51d-81cf852c30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopacities=0\n",
    "for ruta in tqdm(opa['rutas']):\n",
    "    n=ruta.split('/')[-1].replace('.png','')\n",
    "    indice = todas.index[todas['id'] ==n]\n",
    "    n_bb=len(literal_eval(todas['bboxes'][indice[0]]))\n",
    "    nopacities=nopacities+n_bb\n",
    "\n",
    "print('total de opacidades en '+mode+' :', nopacities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21c8dd-7d5e-4eac-9521-53d412c7182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver cantidad de enotaciones sanas por inagen (2 pues es 1 por pulmon)\n",
    "nimages=len(san['rutas'])\n",
    "print('total de anotaciones sanos en '+mode+' :', nimages*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d7f38-db84-46ac-96a6-ba35855a1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los valores calculados:\n",
    "TotOpaTest=885\n",
    "TotSanTest=1772\n",
    "\n",
    "TotOpaVal=1974\n",
    "ToTSanVal=3540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6af78-89b0-4ca8-8014-4c8b999eb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generar conteo reinterpretado de matrices de confusion\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mode='test'\n",
    "model = YOLO('/home/jair/COVID/YOLO8/runs/detect/train/weights/best.pt')\n",
    "Sanos=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+\"_sanos.csv\")\n",
    "S=list(Sanos['rutas'])\n",
    "aciertosS=0\n",
    "fallosS=0\n",
    "for ruta in tqdm(S):\n",
    "    rutam=ruta.replace('rsna640','rsna640opacity')\n",
    "    results=model(rutam,verbose=False)\n",
    "    for r in results:\n",
    "        inf=r.boxes.cls.tolist()\n",
    "        if len(inf)==0:\n",
    "            fallosS=fallosS+2#si no hay prediccion alguna fallo de detectar 2 pulmones sanos\n",
    "        else:\n",
    "            nunos=inf.count(1)\n",
    "            if nunos <=0:\n",
    "                fallosS=fallosS+2#si hay prediccion y ninguna de no opacidad falla al detectar 2 pulmones sanos\n",
    "            if nunos == 1:\n",
    "                fallosS=fallosS+1 # si hay una deteccion de sano falla en detectar el otro\n",
    "                aciertosS=aciertosS+1\n",
    "            if nunos >= 2:\n",
    "                aciertosS=aciertosS+2# si hay mas de dos como sanos puede que detecte pulmones con distinto intervalo de confianza pero clasificacion esta bien \n",
    "\n",
    "                          \n",
    "                \n",
    "model = YOLO('/home/jair/COVID/YOLO8/runs/detect/train/weights/best.pt')\n",
    "Opacity=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+\"_opacity.csv\")\n",
    "O=list(Opacity['rutas'])\n",
    "todas=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/class_opacity.csv\")\n",
    "\n",
    "aciertosO=0\n",
    "fallosO=0\n",
    "\n",
    "for ruta in tqdm(O):\n",
    "    rutam=ruta.replace('rsna640','rsna640opacity')\n",
    "    results=model(rutam,verbose=False)\n",
    "    n=ruta.split('/')[-1].replace('.png','')\n",
    "    indice = todas.index[todas['id'] ==n]\n",
    "    n_bb=len(literal_eval(todas['bboxes'][indice[0]]))\n",
    "    for r in results:\n",
    "        inf=r.boxes.cls.tolist()   \n",
    "        if len(inf)==0:\n",
    "            fallosO=fallosO+n_bb #si no hay prediccion alguna fallo en clasificar todos bboxes\n",
    "        else:\n",
    "            nceros=inf.count(0)\n",
    "            if nceros == n_bb: #si coinciden numero de predicciones y bbxes originales clasifico misma cantidad de veces correctamente\n",
    "                aciertosO=aciertosO+nceros\n",
    "            if nceros < n_bb:   # si hay menos detecciones en 0 que anotaciones entpnces acerto en unas y fallo en otras\n",
    "                fallosO=fallosO+(n_bb-nceros)\n",
    "                aciertosO=aciertosO+nceros\n",
    "            if nceros > n_bb: # si hay mÃ¡s detecciones con clasificacion correcta puede haber varios intervalos de confianza\n",
    "                aciertosO=aciertosO+n_bb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615ecef-6300-463e-b026-c62026f542f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "VP = aciertosO\n",
    "FP = fallosO\n",
    "FN = fallosS\n",
    "VN = aciertosS\n",
    "\n",
    "# Crear la matriz de confusiÃ³n\n",
    "matriz_confusion = [[VP, FP],\n",
    "                    [FN, VN]]\n",
    "\n",
    "# Etiquetas para las clases\n",
    "clases = ['Opacidad', 'Sanos']\n",
    "\n",
    "# ConfiguraciÃ³n del heatmap con Seaborn\n",
    "sns.set(font_scale=1.2)  # Ajusta el tamaÃ±o de la fuente\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Crear el heatmap con etiquetas personalizadas\n",
    "sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\", annot_kws={\"size\": 16},xticklabels=clases, yticklabels=clases)\n",
    "\n",
    "# ConfiguraciÃ³n adicional\n",
    "plt.xlabel('PredicciÃ³n')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.savefig('/home/jair/COVID/YOLO8/runs/detect/train/'+mode+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355430cc-af7e-4da4-b858-186307686274",
   "metadata": {},
   "source": [
    "<h3>Generar matrices de confusiÃ³n para imÃ¡genes con recuadros delimitadores para opacidades y recuadros que encierran el contorno de la imagen para imÃ¡genes sin presenca de opacidades.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f59579-ab1e-48ec-8eee-9c8f232b7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1770/1770 [01:01<00:00, 28.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1202/1202 [00:38<00:00, 30.87it/s]\n"
     ]
    }
   ],
   "source": [
    "#generar conteo reinterpretado de matrices de confusion\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mode='validation'\n",
    "model = YOLO('/home/jair/COVID/YOLO8/runs/detect/train/weights/best.pt')\n",
    "Sanos=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+\"_sanos.csv\")\n",
    "S=list(Sanos['rutas'])\n",
    "aciertosS=0\n",
    "fallosS=0\n",
    "for ruta in tqdm(S):\n",
    "    rutam=ruta.replace('rsna640','rsna640opacity')\n",
    "    results=model(rutam,verbose=False)\n",
    "    for r in results:\n",
    "        inf=r.boxes.cls.tolist()\n",
    "        if len(inf)==0:\n",
    "            fallosS=fallosS+1#si no hay prediccion alguna fallo de detectar imagen sanos\n",
    "        else:\n",
    "            nunos=inf.count(1)\n",
    "            nceros=inf.count(0)\n",
    "            if nunos <=0:\n",
    "                fallosS=fallosS+1#si hay prediccion y ninguna de no opacidad falla al detectar imagen sanos    \n",
    "            if nunos == 1: # si hay una deteccion de sano clasifico bien\n",
    "                aciertosS=aciertosS+1\n",
    "            if nunos >= 2:\n",
    "                aciertosS=aciertosS+1# si hay mas de dos como sanos puede que detecte imagen sana con distinto intervalo de confianza pero clasificacion esta bien \n",
    "\n",
    "                          \n",
    "                \n",
    "model = YOLO('/home/jair/COVID/YOLO8/runs/detect/train/weights/best.pt')\n",
    "Opacity=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/\"+mode+\"_opacity.csv\")\n",
    "O=list(Opacity['rutas'])\n",
    "todas=pd.read_csv(\"/home/jair/COVID/rsna/csv_crean_retina_dataset/class_opacity.csv\")\n",
    "\n",
    "aciertosO=0\n",
    "fallosO=0\n",
    "\n",
    "for ruta in tqdm(O):\n",
    "    rutam=ruta.replace('rsna640','rsna640opacity')\n",
    "    results=model(rutam,verbose=False)\n",
    "    n=ruta.split('/')[-1].replace('.png','')\n",
    "    indice = todas.index[todas['id'] ==n]\n",
    "    n_bb=len(literal_eval(todas['bboxes'][indice[0]]))\n",
    "    for r in results:\n",
    "        inf=r.boxes.cls.tolist()   \n",
    "        if len(inf)==0:\n",
    "            fallosO=fallosO+n_bb #si no hay prediccion alguna fallo en clasificar todos bboxes\n",
    "        else:\n",
    "            nceros=inf.count(0)\n",
    "            if nceros == n_bb: #si coinciden numero de predicciones y bbxes originales clasifico misma cantidad de veces correctamente\n",
    "                aciertosO=aciertosO+nceros\n",
    "            if nceros < n_bb:   # si hay menos detecciones en 0 que anotaciones entpnces acerto en unas y fallo en otras\n",
    "                fallosO=fallosO+(n_bb-nceros)\n",
    "                aciertosO=aciertosO+nceros\n",
    "            if nceros > n_bb: # si hay mÃ¡s detecciones con clasificacion correcta puede haber varios intervalos de confianza\n",
    "                aciertosO=aciertosO+n_bb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5379051d-b61d-4d00-b913-4be77952f033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAANNCAYAAABRP3WiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB670lEQVR4nOzdeVxU9f7H8fcgqwKBGyiISwqaSu5lu0tobribCyqWZWpWZt3q2nor62ZpuZVrlmmZu7ZoYtebVm65G+4rBmqKguwwvz/8MddpwMBBZ4bzej4ePJz5fr/nzOfAveTHz+d8j8lsNpsFAAAAAAbh5ugAAAAAAOBmIgkCAAAAYCgkQQAAAAAMhSQIAAAAgKGQBAEAAAAwFJIgAAAAAIZCEgQAAADAUEiCAAAAABiKu6MDcBb3jP/J0SEAQIm677YgR4cAACXq7Q7hjg6hUD6NRzo6hAKlb5/s6BCcEpUgAAAAAIZCEgQAAADAUGiHAwAAAOxlorbgSvhpAQAAADAUkiAAAAAAhkI7HAAAAGAvk8nREaAYqAQBAAAAMBSSIAAAAACGQjscAAAAYC92h3Mp/LQAAAAAGApJEAAAAABDoR0OAAAAsBe7w7kUKkEAAAAADIUkCAAAAICh0A4HAAAA2Ivd4VwKPy0AAAAAhkISBAAAAMBQaIcDAAAA7MXucC6FShAAAAAAQyEJAgAAAGAotMMBAAAA9mJ3OJfCTwsAAACAoZAEAQAAADAU2uEAAAAAe7E7nEuhEgQAAADAUEiCAAAAABgK7XAAAACAvdgdzqXw0wIAAABgKCRBAAAAAAyFdjgAAADAXuwO51KoBAEAAAAwFJIgAAAAAIZCOxwAAABgL3aHcyn8tAAAAAAYCkkQAAAAAEOhHQ4AAACwF7vDuRQqQQAAAAAMhSQIAAAAgKHQDgcAAADYi93hXAo/LQAAAACGQhIEAAAAwFBohwMAAADsRTucS+GnBQAAAMBQSIIAAAAAGArtcAAAAIC93HhYqiuhEgQAAADAUEiCAAAAABgK7XAAAACAvdgdzqXw0wIAAABgKCRBAAAAAAyFdjgAAADAXiZ2h3MlVIIAAAAAGApJEAAAAABDoR0OAAAAsBe7w7kUfloAAAAADIUkCAAAAICh0A4HAAAA2Ivd4VwKlSAAAAAAhkISBAAAAMBQaIcDAAAA7FUKd4ebPn269u3bp3379unEiRNyc3PTvn37rnnM8ePH9fHHH2vjxo06f/68/P39VbduXY0ePVoNGjSwWpuQkKAPPvhAGzduVFpammrWrKkBAwaoV69eBZ57y5YtmjRpknbv3i1JatiwoUaNGqVmzZoV+9pIggAAAADYeP/99+Xv76969eopLS1N58+fv+b6X3/9VU888YQqV66sPn36KDg4WBcvXtTevXt19uxZq7WJiYnq06ePUlJSNGjQIIWGhiouLk5jx45VUlKSRo4cabX+p59+0rBhwxQUFKSRI0fK09NTCxcu1KBBgzRjxgzdddddxbo2k9lsNhfriFLqnvE/OToEAChR990W5OgQAKBEvd0h3NEhFMon6j1Hh1Cg9DXPXfexJ06cUFhYmCQpJiZG27ZtK7QSdOHCBXXo0EHh4eGaPn26vLy8rnnu559/XsuXL9ekSZMUFRVlGR82bJh++uknff/996pWrZokKTc3Vw8++KAuXLigb775RlWrVpUkpaSkqGPHjvL29tb3338vN7eiV+NKX90OAAAAuNlMJuf8skN+AlQUX375pc6fP68XXnhBXl5eyszMVFZWVoFr09PTtXr1aoWGhlolQJIUGxurnJwcrVy50jK2detWJSQkqH379pYESJL8/PzUq1cvHT9+XL/99luxro12OAAAAKCUatOmzTXn4+LiSuRz1q9fr3LlyikjI0M9e/a03LcTHh6ukSNHql27dpa1Bw4cUEZGhho1amRznsaNG8tkMmnXrl2WsZ07d1rmClovSbt37y7WvUFUggAAAADY5fDhw8rLy9OQIUNUvXp1ffjhh3rllVd04cIFjRo1SitWrLCsTUxMlCQFBwfbnMfT01OBgYFKSkqyjOW/DgqybfPOP0f+OYuKShAAAABgLyfdHa6kKj1/5/Lly8rNzVWnTp30/vvvW8Zbtmypzp07a/z48ercubNMJpPS09MlXUl4CuLl5WVZI+ma6/PvPbp6fVE4508LAAAAgMvIT0a6d+9uNV6rVi01btxYSUlJOnLkiCTJx8dHkgq9ZygzM9Oy5u/WZ2ZmWq0pKpIgAAAAAHapUqWKJKlSpUo2c/ljFy9elHTtFrasrCxduHDBqvUt//XVLXL5rtVady0kQQAAAIC9HL0L3A3YHa44br/9dknSH3/8YTOXP1axYkVJVzZL8PLy0o4dO2zW7tixQ2azWZGRkZax/Nfbt28vcL105cGpxUESBAAAAMAu3bp1kyQtWLBAVz+GdO/evdqxY4dq1apl2XLbx8dHUVFROnXqlNasWWN1ntmzZ8vd3V2dOnWyjDVv3lwhISH6/vvvrZKs1NRUff3116pWrZqaNGlSrHjZGAEAAACAjWXLlun06dOSpISEBJnNZk2dOtUyP3z4cMvrFi1aqGfPnlq0aJEeeeQRtWnTRufOndO8efPk7u6uV1991erco0eP1i+//KLnn39ee/fuVWhoqOLi4vTjjz9q+PDhVs8oKlOmjF599VU98cQT6t+/v2JiYuTh4aGvvvpK586d0yeffFKsB6VKksl8dapmYPeM/8nRIQBAibrvNtutRAHAlb3dIdzRIRTKp8OHjg6hQOnfPnXdx8bExGjz5s2Fzu/fv9/qfW5urubNm6dFixbp2LFj8vLyUtOmTTVixAir9rZ8J0+e1IQJE7Rx40alpaWpRo0aGjBggPr06VPg5/3666+aMmWK9uzZI0lq0KCBnnzySbVo0aLY10YS9P9IggCUNiRBAEobkqDisycJKs24JwgAAACAoXBPEAAAAGCvm7gTG+xHJQgAAACAoZAEAQAAADAU2uEAAAAAe5moLbgSfloAAAAADIUkCAAAAICh0A4HAAAA2It2OJfCTwsAAACAoZAEAQAAADAU2uEAAAAAe/GwVJdCJQgAAACAoZAEAQAAADAU2uEAAAAAe7E7nEvhpwUAAADAUEiCAAAAABgK7XAAAACAvdgdzqVQCQIAAABgKCRBAAAAAAyFdjgAAADAXuwO51L4aQEAAAAwFJIgAAAAAIZCEgQAAADAULgnCAAAALAXW2S7FCpBAAAAAAyFJAgAAACAodAOBwAAANjJRDucS6ESBAAAAMBQSIIAAAAAGArtcAAAAICdaIdzLVSCAAAAABgKSRAAAAAAQ6EdDgAAALAX3XAuhUoQAAAAAEMhCQIAAABgKLTDAQAAAHZidzjXQiUIAAAAgKGQBAEAAAAwFNrhAAAAADvRDudaqAQBAAAAMBSSIAAAAACGQjscAAAAYCfa4VwLlSAAAAAAhkISBAAAAMBQaIcDAAAA7EQ7nGuhEgQAAADAUEiCAAAAABgK7XAAAACAveiGcylUggAAAAAYCkkQAAAAAEOhHQ4AAACwE7vDuRYqQQAAAAAMhSQIAAAAgKHQDgcAAADYiXY410IlCAAAAIChkAQBAAAAMBTa4QAAAAA70Q7nWqgEAQAAADAUkiAAAAAAhkI7HAAAAGAn2uFcC5UgAAAAAIZCEgQAAADAUGiHAwAAAOxFN5xLoRIEAAAAwFBIggAAAAAYCu1wAAAAgJ3YHc61UAkCAAAAYCgkQQAAAAAMhXY4AAAAwE60w7kWKkEAAAAADIUkCAAAAICh0A4HAAAA2Il2ONdCJQgAAACAoZAEAQAAADAU2uEAAAAAe9EN51KoBAEAAACwMX36dD399NOKiopS3bp1ddtttxX52KSkJDVr1kwRERGaOnVqgWsSEhL07LPP6s4771RkZKSio6P19ddfF3rOLVu2aODAgWrcuLEaN26sgQMHauvWrcW+LolKEAAAAIACvP/++/L391e9evWUlpam8+fPF/nY1157Tbm5uYXOJyYmqk+fPkpJSdGgQYMUGhqquLg4jR07VklJSRo5cqTV+p9++knDhg1TUFCQRo4cKU9PTy1cuFCDBg3SjBkzdNdddxXr2kiCAAAAADuVxt3hfvjhB4WFhUmSYmJiipwEffPNN1q/fr2ee+45vfPOOwWu+eCDD3T27FlNmjRJUVFRkqTevXtr2LBhmjZtmqKjo1WtWjVJUm5url599VV5enpq3rx5qlq1qiSpa9eu6tixo1577TV9//33cnMrepMb7XAAAAAAbOQnQMVx/vx5vfnmmxo4cGCh7XPp6elavXq1QkNDLQlQvtjYWOXk5GjlypWWsa1btyohIUHt27e3JECS5Ofnp169eun48eP67bffihWnU1WCli1bdl3Hde3atUTjAAAAAEqDNm3aXHM+Li6uRD/vrbfeko+Pj0aNGqXdu3cXuObAgQPKyMhQo0aNbOYaN24sk8mkXbt2WcZ27txpmStovSTt3r1bzZo1K3KcTpUEvfDCCzKZTDKbzZaxq0uL+eN/LTeSBAEAAMCRSmM7XHGtX79eq1at0owZM1S2bNlC1yUmJkqSgoODbeY8PT0VGBiopKQky1j+66CgIJv1+efIP2dROVUS9Nlnn1m9z83N1fjx43XmzBn1799ftWvXliQdPHhQ8+fPV1BQkJ599llHhAoAAAA4vZKu9BQmNTVVr7zyijp16qT77rvvmmvT09MlXUl4CuLl5WVZ83frvby8rNYUlVMlQS1atLB6P3XqVKWkpOibb76Rv7+/Zbxt27bq27evevXqpZ07d6ply5Y3O1QAAAAA/+/f//63MjIy9NJLL/3tWh8fH0lSVlZWgfOZmZkKDAws0vrMzEyrNUXl1BsjLF68WD179rRKgPIFBASoZ8+eWrRokQMiAwAAAP7HZDI55dfNsHfvXi1cuFD9+vVTamqqjh8/ruPHj1va2C5evKjjx48rNTVV0rVb2LKysnThwgWr1rf811e3yOW7VmvdtTh1EnTmzJlCy2TSlZJYQd8MAAAAADfHH3/8IbPZrKlTpyoqKsry9dxzz0mSPv30U0VFRVl2fAsPD5eXl5d27Nhhc64dO3bIbDYrMjLSMpb/evv27QWul6SGDRsWK2anaof7q5CQEH3zzTfq37+/PDw8rOaysrK0atUqq23yAAAAANxcDRs21IcffmgzfujQIU2aNEkdO3ZUVFSU6tevL+lK61p+UrRmzRqrbbJnz54td3d3derUyTLWvHlzhYSE6Pvvv9eoUaNUpUoVSVfuQ/r6669VrVo1NWnSpFgxO3US1K9fP7399tuKiYnRkCFDdOutt0q68g2dPXu29u3bpxdffNHBUQIAAMDoSuPucMuWLdPp06clSQkJCZZqT77hw4dLutKu1r59e5vjN23aJEmqXbu2zfzo0aP1yy+/6Pnnn9fevXsVGhqquLg4/fjjjxo+fLjVM4rKlCmjV199VU888YT69++vmJgYeXh46KuvvtK5c+f0ySefFOtBqZKTJ0EDBw7UmTNnNHv2bD311FM287GxsRo4cKADIgMAAABKt8WLF2vz5s1WY1dXfPKToOtRtWpVffnll5owYYK+/PJLpaWlqUaNGnrjjTfUp08fm/X333+/Zs+erSlTpuijjz6SJDVo0EBz5syx2VytKEzmqx/K46ROnDihH374QSdOnJB05em1bdu2VfXq1UvsM+4Z/1OJnQsAnMF9t9k+TwEAXNnbHcIdHUKhqj6+xNEhFOj0J90dHYJTcupKUL6wsDA98sgjjg4DAAAAKFjp64Yr1Zx6dzgAAAAAKGlOXwm6dOmSFi1apJ07d+rixYvKy8uzmjeZTJo7d66DogMAAADgapw6Cfrjjz/Ut29fJSYmys/PT6mpqbrlllt06dIl5eXlKTAwsNhPhwUAAABKWmncHa40c+p2uA8//FDJycmaM2eOVq9eLbPZrAkTJmjbtm169NFHVa5cOS1YsMDRYQIAAABwIU6dBP3888/q2bOnWrZsaZVd+/j4aMyYMbr11lv1/vvvOzBCAAAAAK7GqZOg8+fPKyIiQpLk7n6lcy8zM9Myf88992jjxo0OiQ0AAADIZzKZnPILBXPqJCggIEApKSmSJF9fX3l4eFieWitd+R/b5cuXHRUeAAAAABfk1ElQzZo1dejQIUlXEp769etr6dKlysrKUnp6upYsWaKwsDAHRwkAAADAlTh1EnT33XdrzZo1lha4Rx99VLt371aLFi1011136ffff9fgwYMdGyQAAAAMz9Ftb7TDFY9Tb5H9+OOPa8iQIfL09JQktW3bVpMnT9by5cvl5uam9u3b66GHHnJwlAAAAABciVMnQSaTyZIA5Wvbtq3atm3roIgAAAAAuDqnToIAAAAAl0DnmUtxqiRo8uTJxT7GZDJpxIgRNyAaAAAAAKWR0ydB+Td0mc1mm3Gz2UwSBAAAAKBYnCoJiouLs3qfkZGh559/Xnl5eRoyZIjq1KkjSTpw4IBmz54td3d3vfvuu44IFQAAALBgJzbX4lRJUEhIiNX7d955R2azWV999ZXVBgl169ZVu3bt9PDDD2vRokX6xz/+cbNDBQAAAOCinPo5Qd9++606d+5ss0OcJHl5ealLly765ptvHBAZAAAAAFflVJWgv0pOTlZ2dnah89nZ2UpOTr55AQEAAAAFoB3OtTh1JahmzZpasmSJLl++bDOXmpqqxYsXq2bNmg6IDAAAAICrcupK0NChQzVmzBh16dJFAwYMUK1atSRJhw8f1rx58/THH3/ovffec3CUKC2qBfqoRY1ARQT5KiLIV9UrlJW7m0kzNhzT3F9PFnhMZT9PtaxZ3nJMzYrl5OnuppW7EvXumoPF+vw7awZqfI8GkqStxy/o6a/32KypUaGsukQGK7yyr6rc4qVbfDxkknQ2NUs7Tl3Uwm0JOnIurdjXDsCY0i6c0f51S3Rm/w6lJZ+VzGZ5+weqYq0GqvNAVwWEWP9DY+LvW5Ww82clJxxVxsU/lZWWIjd3D5WrEKzg25qpzv3R8vK9xeZzMi9f0h97Nyv55GFdOHVIFxOOKDc7S5Xq3K77hr95sy4XACycOgnq1KmTUlJS9N577+ndd9+12i7bx8dHY8eOVadOnRwcJUqLbo2qqHfTkL9feJX761TUU61vtfuz/bzc9Y+oOsozm+V2jXJ6g6p+6t00RH9eztKJ8+naczpF3h5uqlWxnDo1DFb72yrrze8OaG38WbtjAlC6nT++Xz9Ne1k5menyuaWCgiIay2RyU3LCEZ3Yuk4nf1uvFjFjFNroHssxJ7at18lt/1G5ilXkX6W6vHz9lXk5RRdOHND+tV/r2K8/6L7hb8q/SnWrzzp3ZK+2LfjwZl8icFPRDudanDoJkqS+ffuqc+fO2rBhg06cOCFJCgsL0z333CNfX18HR4fS5Mi5y5q/5ZQOJqVq/5lUDbyjmtrXD7rmMX9czNDXvyXoQFKqDiSlqnVEJQ1qGVbsz366za0KLOep5Tv/ULdGVQtdt/V4svrN3qoT59Otxk2SHm4WohEP1NI/2tXRpqMXlJKZU+w4ABjHbwsnKyczXTVbtlOjHsPkVubKXwnMeXna9/18xf/wlX5bOFlV6rdQGY8rGxSFt+qmyC5D5O0faHWunMx0bV3woRJ2btS2ryap1dPjrea9/QJVs2V7BYTeqsDQW3Xh1CFt/3rqzblQACiA0ydBkuTr66v27ds7OgyUcqt2J1m9zzMXsvAqGw6f14bD5y3v7w8vwkF/cV/tCmp3W2V9sfmkjv2Zpm6NCl+beCmzwHGzpAVbE9S1URWFBPgoMsRfG4+cL3AtAGRevqSLp49Jkup3iLEkQJJkcnPTbe376uB/lio7/bJSkk4qIPRKxTsgpFaB53P38lFk9CNK2LlR54/vV3ZGmjy8y1rmK9Soqwo16lreX0w8fgOuCgCKzqk3RgBKu1t83DXmwdo6/meaZm20/y8Fuf+fuWXl5tl9LgClVxl3jyKv9SznX6R1Jrcy+S/klv8aMBCTyeSUXyiYU1WCBg4cKJPJpFmzZsnd3V0DBw7822NMJpPmzp17E6IDSt6YtrV1i4+H/rn8d2XlFr+KdLUukcEKK19W5y9nae8fKSUUIYDSyN3LRxVr1de5I3u199vPC2iHW6Dc7CwF1WuqsoGV/vZ8uTnZ2vvtZ5KkoIhGKuPpdUPjBwB7OVUSdOrUKZlMJpnNZst7oLRqE1FJrSIqaeG2BO0+falYx3q5u+nZtrUlSb5eZVSzYjlVC/TRn5ez9PKK35WWlXsjQgZQijTpM1Ibp7+uo7+sVuK+rQqoVlsmNzclnzqijIt/KqxZKzXqMazAYy+cPKTDP62U2SxlXr6oCycOKuvyJQWG1VHTPqNu8pUAQPE5VRK0bt26a74HSovyZT00uu2tOnUhXZ/8dKzYx3uUMalDA+tNGxKS0/XO6oPalVC8hAqAMflVDtUDT72nLV98oDP7tyv94p//mwuqpkq1G1rd13O1tOSzOr7F+r/RlcMbqXGvEfIJqHBD4wacFp1nLsWpkiDAKJ6PqiM/b3eNXfG7MnOKf/9Oamau7hn/kyQpsKyHIoJ8FdsyTJP6RGr+llOauv5oSYcMoJQ5d2Sffp0zTqYybmoRM0aV6kTKrYyH/jy6T7uWz9K2Lz/Sn0d/V9OHbSs7IQ1bqseElTLn5Sot+U+dObBDv38/X2v/PULN+o1WaKO7HXBFAFB0Tr0xQnJysuLj4wudj4+P18WLF29iRID92tevrHtqV9DynX9o+0n7//d7IS1bvx69oBFf7tKBpFT1ax6qu2qVL4FIAZRWWemp+nXO28q8fFEtY19StSb3y9svUJ5lfVWlfgvd/djrKuPppWObftCZg7sKPY/JrYzKla+smndG6f5R70omk7Z9+aEyLl24iVcDAMXn1JWg8ePHa8+ePVq2bFmB8y+++KIiIyP1+uuv39zAADvcV/tKq0jdYD9N6tPQaq582SvP4ogI8rXMvboyXufTsv/2vDl5Zv3w+xmFB/nqvjoV9DNbZAMoROK+rcpMvahyFauofPUIm3nfisEqHxahs4d26cyBHapcJ/Jvz1mufJAq1W6oxH1blbR/u6o3b30jQgecFjuxuRanToJ+/fVXde7cudD51q1ba+XKlTcxIqDk1Av2K3TOz9tDjasFSJI83YtesE3PvtJaF1i26NvfAjCetAtnJUkeXj6FrvHwuXI/UFZaapHP6+7pLUnKTKVLA4Bzc+ok6MyZM6patWqh88HBwTpz5sxNjAiw30vLfy907qH6lfXPhyK09fgFPf31nmKfu2n1AEnSyQvp1xseAAPwueVKRTrlzCllp1+Wh085q/m83Bwlnzos6UqFpyhyc7J17ug+SZJvpZASjBYASp5T3xPk7e2txMTEQucTExPl7u7UeRxQono1qarKfp42417ubhp0ZzW1Cq+onNw8fbMnyQHRAXAVwfWaqoynt3Kzs7Ttq0nKyfzfP5zk5WRr57KZSrtwVqYy7gq5/comBxkpyTq88VtlZ6TZnC89+U9tmfe+Mi6eV9nylRUU0ehmXQrgNBz9UFQello8Tp1B3HbbbVq1apWGDh0qb29vq7nMzEytWrVK9erVc1B0KG3CK5ezPHtHkqoGXGkT6RJZxWqjgZeW79Ofl6/co1OhnIfejr7NMlfJ78oDAu+pXV61Kt5uGX9/7SEdOHPZ7hh7Nw3Rk61q6fifaTpxPl1ZuXmqUM5TtSuVk7+PhzJz8vTvNQd19JztX1IAIJ+X7y1q0mu4ti74UAk7N+rc4T0KrFZHpjJllHzy0JXtsk1uatTtMflWDJYk5WZnaseiadq1dIZuCamlcuUry2w2Kz35nJJPHVZebo68bymvlkPGqoyH7T/W/DhxjOV1frvchZMHrcbrPthHVeo3v8FXDwBOngTFxMRoxIgRio2N1bPPPmtJeH7//Xd98MEHOnHihMaMGfM3ZwGKppyXu+pX9bcZD/L3UpD//55+7lHGzep1QccElvVUYNn//SWgnFfJ/F9t+k/H1LxGoOoG++r20Fvk6+2ujOxcJSRnaNWeJC3b8YdOX8wokc8CULqFNWsl/yo1dOi/y3Xu8F6dObhTMpvl7V9e1Zo+oNr3dlb56uGW9V6+t6hh9CM6d3iPLiWeUErSSeVmZ8nDp5zK14hQlfotVLNl+0KfLXT++H6bsZyMNKvxzMvcSwTg5jCZzWazo4O4lg8//FDTpk2zKeeZzWY9/vjjeuaZZ0rkc/KfuQIApcV9txXtXg4AcBVvdwj/+0UOUnvMd44OoUCHxj/k6BCcklNXgiTpqaeeUuvWrbVixQodP35cklSjRg117txZDRs2/JujAQAAAMCa0ydBktSwYUMSHgAAAAAlwiWSIAAAAMCZsROba3H6JCg3N1dr167Vzp07dfHiReXl5VnNm0wmvf322w6KDgAAAICrceok6OLFixo8eLDi4+NlNptlMpmUv49D/muSIAAAAADF4dQPS/3oo4908OBB/etf/9IPP/wgs9msmTNn6ptvvtFDDz2kyMhIbd682dFhAgAAwOBMJuf8QsGcOgn68ccf1aVLF/Xs2VO+vr6SpDJlyujWW2/VBx98IHd3d02cONGxQQIAAABwKU6dBJ05c0aRkZGSJHf3K517WVlZlvkHH3xQa9eudUhsAAAAAFyTU98T5Ofnp8zMTElS2bJl5e7urjNnzljmvb29lZyc7KDoAAAAgCvYHc61OHUlKCwsTMeOHZN0pQ2uTp06+v777yVJeXl5Wr16tapUqeLACAEAAAC4GqdOglq2bKkffvhBubm5kqS+fftq48aNatu2raKiorRp0yb16tXLwVECAAAAcCVO3Q43dOhQdenSxbItdu/evZWenq7ly5fLzc1NDz/8sB555BEHRwkAAACjoxvOtTh1ElSuXDnVqlXLamzQoEEaNGiQgyICAAAA4Oqcuh0OAAAAAEqaU1eCJCk9PV2zZs3SmjVrdOLECUlXNkyIiorSkCFDVLZsWQdHCAAAAKNzc6MfzpU4dRJ0/vx5xcTE6PDhw/L399ett94qSTp58qQmT56sb7/9VvPmzVP58uUdHCkAAAAAV+HUSdB7772nI0eO6IUXXlD//v3l4eEhScrOztYXX3yhd999V++9957GjRvn4EgBAAAAuAqnToJ+/PFHdevWTYMHD7Ya9/Dw0ODBg7V//36tW7fOMcEBAAAA/4/d4VyLU2+MkJmZqcjIyELnIyMjlZWVdRMjAgAAAODqnDoJqlu3rg4dOlTo/OHDh1W3bt2bGBEAAAAAV+fUSdDTTz+tJUuW6IcffrCZW716tZYsWaJnnnnGAZEBAAAA/2MymZzyCwVz6nuCli1bpmrVqmnUqFGqUaOGateuLUk6dOiQjh07pvDwcC1dulRLly61HGMymfT22287KmQAAAAATs6pk6Crk5ujR4/q6NGjVvP79+/X/v37rcZIggAAAABci1MnQfHx8Y4OAQAAAPhbdJ65Fqe+JwgAAAAASppTV4IkKTExUfv371dKSor8/PwUERGh4OBgR4cFAAAAwEU5bRK0ZcsWvffee9q9e7fNXGRkpMaMGaPmzZs7IDIAAADAGjuxuRanTIKWLFmil19+Wbm5uWrUqJEaNGggX19fpaamas+ePdqxY4cGDx6sN998U926dXN0uAAAAABciNMlQYcPH9Yrr7yiGjVq6P333y/wYajx8fEaM2aMXn75ZUVGRurWW291QKQAAAAAXJHTbYwwZ84clStXTnPnzi0wAZKkunXr6tNPP1W5cuX06aef3twAAQAAgL9w9ENReVhq8ThdEvTrr7+qW7duqlix4jXXVaxYUV27dtUvv/xykyIDAAAAUBo4XRJ05swZ1a5du0hr69SpozNnztzgiAAAAACUJk53T5CXl5fS09OLtDYjI0NeXl43OCIAAADg2ug8cy1OVwmqWbOmNm7cWKS1GzZsUM2aNW9wRAAAAABKE6dLgqKiorR+/XqtXr36muvWrFmj9evXKyoq6iZFBgAAAKA0cLokaMCAAQoLC9Po0aP1zjvv6NixY1bzx48f17vvvqvRo0crLCxM/fv3d0ygAAAAwP9z9C5w7A5XPE53T5C3t7dmzpypYcOG6dNPP9XcuXNVrlw5+fn5KTU1VampqTKbzapVq5Y+/vhj+fj4ODpkAAAAAC7E6ZIgSapWrZqWLl2qr7/+Wt9//70OHjyos2fPqly5cmrWrJnat2+vnj17sikCAAAAgGJzyiRIkjw9PdW/f3/a3QAAAOD06DxzLU6bBAEAAABwnOnTp2vfvn3at2+fTpw4ITc3N+3bt6/AtZs3b9bq1au1ZcsWnT59WpIUFhamzp07q2/fvvL29rY55sKFC5o4caLi4uKUnJyskJAQ9ezZU7GxsXJ3t01T4uPjNXHiRG3btk3Z2dkKDw/XY489prZt2xb72kiCAAAAANh4//335e/vr3r16iktLU3nz58vdO348eN1+vRpPfjgg+rXr5+ys7MVFxend955RytXrtSCBQusbmVJTU3VgAEDdPToUfXr108RERHasmWLxo8fryNHjmjcuHFW54+Pj1ffvn3l6emp2NhYBQYGasWKFRoxYoTGjRun7t27F+vaSIIAAAAAO5XGndh++OEHhYWFSZJiYmKumQQ9++yzatq0qVUFJyYmRs8++6xWrVqlRYsWWd3mMmvWLB06dEgvvPCCYmNjJUm9evWSn5+f5s2bp+7du6t58+aW9f/617+Unp6uzz77TA0bNpQk9ezZU71799a4ceMUFRUlX1/fIl+b022RDQAAAMDx8hOgorjjjjsKbGHr0KGDJGn//v1W48uXL5ePj4/69u1rNZ6fEC1btswydurUKW3dulXNmze3JECS5OHhoZiYGF26dElxcXFFjlWiEgQAAACUWm3atLnmfHGTh+JKSkqSJFWsWNEydu7cOSUkJKhx48Y29wqFhoaqUqVK2rVrl2Us/3WTJk1szt+4cWNJ0u7duxUdHV3kuEiCAAAAADuVwm44u6WmpmrmzJny8PBQ586dLeOJiYmSpODg4AKPCw4O1okTJ2zWBwUFFbj26jVFRRIEAAAAlFI3utJTmJycHD3zzDNKSEjQiy++qJo1a1rmMjIyJF15JE5BvLy8lJ6ebnmf/7qg9fmbLVy9vii4JwgAAABAicnJydGzzz6r//73v3r00Uc1ePBgq/n8FrisrKwCj8/MzJSPj4/lff7rgtZnZmZarSkqKkEAAACAnUrj7nDXIzs7W88++6xWr16txx9/XKNHj7ZZ83ctbImJiVatb/nr8+8v+uvaq9cUFZUgAAAAAHbLysrSU089pdWrV2vkyJEFJkDSlU0Sqlatqvj4eEtrXL6EhASdPXtWkZGRlrH8HeG2b99uc64dO3ZYrSkqkiAAAAAAdsnKytKoUaMUFxenZ555Rk8++eQ113fp0kXp6elasGCB1ficOXMkyWqnt2rVqqlJkybavHmz9uzZYxnPycnR559/Lj8/P7Vu3bpY8dIOBwAAANipNHbDLVu2TKdPn5Z0pUJjNps1depUy/zw4cMtr8eMGaMff/xRTZo0UZUqVbR8+XKrc4WFhVm2s5akoUOHavXq1XrvvfeUkJCgiIgIbdmyRcuXL1d0dLRatGhhdfzYsWM1YMAAPfLIIxo8eLACAwO1fPly7d27V2+99Zb8/PyKdW0ms9lsLtYRpdQ9439ydAgAUKLuu812K1EAcGVvdwh3dAiFavH2fxwdQoE2v/TAdR8bExOjzZs3Fzp/9QNQW7durYSEhELXduvWTe+8847V2Pnz5zVx4kStW7dOycnJCgkJUY8ePTRkyJACH7waHx+vCRMmaNu2bcrOzlZ4eLiGDh2qqKioYl8bSdD/IwkCUNqQBAEobUiCis+eJKg0ox0OAAAAsBO7w7kWNkYAAAAAYCgkQQAAAAAMhXY4AAAAwE50w7kWKkEAAAAADIUkCAAAAICh0A4HAAAA2Ind4VwLlSAAAAAAhkISBAAAAMBQaIcDAAAA7EQ3nGuhEgQAAADAUEiCAAAAABgK7XAAAACAndgdzrVQCQIAAABgKCRBAAAAAAyFdjgAAADATnTDuRYqQQAAAAAMhSQIAAAAgKHQDgcAAADYid3hXAuVIAAAAACGQhIEAAAAwFBohwMAAADsRDuca6ESBAAAAMBQSIIAAAAAGArtcAAAAICd6IZzLVSCAAAAABgKSRAAAAAAQ6EdDgAAALATu8O5FipBAAAAAAyFJAgAAACAodAOBwAAANiJbjjXQiUIAAAAgKGQBAEAAAAwFNrhAAAAADuxO5xroRIEAAAAwFBIggAAAAAYCu1wAAAAgJ3ohnMtVIIAAAAAGApJEAAAAABDoR0OAAAAsJMb/XAuhUoQAAAAAEMhCQIAAABgKLTDAQAAAHaiG861UAkCAAAAYCgkQQAAAAAMhXY4AAAAwE4m+uFcCpUgAAAAAIZCEgQAAADAUGiHAwAAAOzkRjecS6ESBAAAAMBQSIIAAAAAGArtcAAAAICd2B3OtVAJAgAAAGAoJEEAAAAADIV2OAAAAMBOdMO5FipBAAAAAAyFJAgAAACAodAOBwAAANjJJPrhXAmVIAAAAACGQhIEAAAAwFBohwMAAADs5EY3nEuhEgQAAADAUEiCAAAAABgK7XAAAACAnUw8LdWlUAkCAAAAYCgkQQAAAAAMhXY4AAAAwE50w7kWKkEAAAAADIUkCAAAAICh0A4HAAAA2MmNfjiXQiUIAAAAgKGQBAEAAAAwFNrhAAAAADvRDedaqAQBAAAAMBSSIAAAAACGQjscAAAAYCdTKeyHmz59uvbt26d9+/bpxIkTcnNz0759+wpdn5OTo9mzZ2vx4sVKSEhQQECA2rRpo6efflqBgYE26y9cuKCJEycqLi5OycnJCgkJUc+ePRUbGyt3d9s0JT4+XhMnTtS2bduUnZ2t8PBwPfbYY2rbtm2xr40kCAAAAICN999/X/7+/qpXr57S0tJ0/vz5a65/8cUXtWLFCrVq1UqPPPKITp06pblz5+q3337TV199pbJly1rWpqamasCAATp69Kj69euniIgIbdmyRePHj9eRI0c0btw4q3PHx8erb9++8vT0VGxsrAIDA7VixQqNGDFC48aNU/fu3Yt1bSRBAAAAAGz88MMPCgsLkyTFxMRcMwn65ZdftGLFCrVu3VrTpk2zjNevX1+jRo3S7NmzNXLkSMv4rFmzdOjQIb3wwguKjY2VJPXq1Ut+fn6aN2+eunfvrubNm1vW/+tf/1J6ero+++wzNWzYUJLUs2dP9e7dW+PGjVNUVJR8fX2LfG3cEwQAAADYyWRyzi975CdARbF8+XJJsiQ0+dq1a6eQkBDL/NXrfXx81LdvX6vx/OOXLVtmGTt16pS2bt2q5s2bWxIgSfLw8FBMTIwuXbqkuLi4IscqkQQBAAAAsNPOnTvl5uamRo0a2cw1btxYJ06cUHJysiTp3LlzSkhIUN26deXt7W21NjQ0VJUqVdKuXbssY/mvmzRpUuC5JWn37t3Fipd2OAAAAKCUatOmzTXni1tBKUxiYqICAwPl6elpMxcUFGRZExAQoMTERElScHBwgecKDg7WiRMnrM599Xn+uvbqNUVFEgQAAADYya0U7g5XHBkZGbrlllsKnPPy8rKsufrPghKm/PXp6emW9/mvC1qff+6r1xcFSRAAAABQSpVUpefveHt7Kysrq8C5zMxMy5qr/7zWeh8fH8v7/NcFrc8/99Xri4J7ggAAAADYJTg4WBcuXCgwUUlKSrKsufrPwlrYEhMTrVrf8tfnn+eva69eU1QkQQAAAICdTE76dbNERkYqLy9PO3futJnbvn27wsLCFBAQIEmqWLGiqlatqvj4eEtrXL6EhASdPXtWkZGRlrH8HeG2b99uc+4dO3ZYrSkqkiAAAAAAdomOjpYkzZ4922p8zZo1SkhIsMzn69Kli9LT07VgwQKr8Tlz5lidT5KqVaumJk2aaPPmzdqzZ49lPCcnR59//rn8/PzUunXrYsXLPUEAAAAAbCxbtkynT5+WdKVCYzabNXXqVMv88OHDLa/vuusuderUSatWrdKwYcPUpk0bnTp1Sp9++qlq165t8/ygoUOHavXq1XrvvfeUkJCgiIgIbdmyRcuXL1d0dLRatGhhtX7s2LEaMGCAHnnkEQ0ePFiBgYFavny59u7dq7feekt+fn7FujaT2Ww2F/cbUhrdM/4nR4cAACXqvttstxIFAFf2dodwR4dQqL6f7XB0CAVaMLDRdR8bExOjzZs3Fzq/f/9+q/fZ2dmaPXu2lixZooSEBAUEBKh169Z6+umnVb58eZvjz58/r4kTJ2rdunVKTk5WSEiIevTooSFDhsjd3bZWEx8frwkTJmjbtm3Kzs5WeHi4hg4dqqioqGJfG0nQ/yMJAlDakAQBKG1IgorPniSoNOOeIAAAAACGwj1BAAAAgJ3cjP2sVJdDJQgAAACAoZAEAQAAADAU2uEAAAAAO5lM9MO5kmIlQQMHDryuDzGZTJo7d+51HQsAAAAAJalYSVBh+4SbTCYVtNN2/jiZMQAAAABnUawkKD4+3up9VlaWnn76aR08eFDDhw9XixYtVKlSJZ09e1abNm3Sxx9/rDp16mjixIklGTMAAADgVPg3f9di18YIU6dO1Z49e7R48WJ169ZNISEh8vT0VEhIiLp3766FCxdq165dmjp1aknFCwAAAAB2sSsJWrlypaKiouTv71/gfEBAgNq1a6cVK1bY8zEAAAAAUGLs2h3uzJkz8vDwuOYaDw8PnT171p6PAQAAAJwa98C7FrsqQcHBwVq3bp2ysrIKnM/KylJcXJyCgoLs+RgAAAAAKDF2JUFdu3bV8ePHNWjQIG3ZskW5ubmSpNzcXG3evFmDBg3SyZMn1a1btxIJFgAAAADsZVc73GOPPaa9e/dq3bp1GjhwoNzc3HTLLbfo4sWLysvLk9lsVuvWrfXYY4+VVLwAAACA03GjG86l2JUEeXh4aOrUqVq5cqWWLFmiffv26eLFi/L19VX9+vXVvXt3derUqaRiBQAAAAC72ZUE5evcubM6d+5cEqcCAAAAgBuqRJIgAAAAwMjYHc612LUxAgAAAAC4GrsrQWfOnNG0adO0YcMGJSUlKTs722aNyWTSvn377P0oAAAAALCbXUlQUlKSevbsqT///FO1a9dWVlaWqlatKk9PT506dUo5OTmqV6+efH19SypeAAAAwOnQDOda7GqHmzJlis6dO6eZM2dqxYoVkqTu3bvr+++/19q1a3XPPfcoIyNDkydPLpFgAQAAAMBediVBGzZs0L333qu77rrLZi44OFgffvihMjMzNWnSJHs+BgAAAABKjF1J0NmzZ1W7dm3L+zJlyigzM9Pyvly5crrrrrsUFxdnz8cAAAAATs3NZHLKLxTMriTI19fXaiMEf39/JSUlWa3x8/PT+fPn7fkYAAAAACgxdiVBVatWVWJiouV93bp19euvvyo9PV2SlJeXpw0bNig4ONi+KAEAAACghNiVBLVs2VKbNm2yVIO6du2qM2fO6OGHH9a7776rvn376tChQ3rooYdKJFgAAADAGZlMzvmFgtm1RXbPnj3l7++vCxcuqHLlyoqOjtbevXs1b9487d+/X5LUsWNHPfHEEyUSLAAAAADYy64kqEaNGnrsscesxl566SUNGzZMJ0+eVEhIiCpWrGhXgAAAAABQkuxKggpTvnx5lS9f/kacGgAAAHA6JnrPXIpd9wQBAAAAgKspViXoxRdfvK4PMZlMevvtt6/rWAAAAAAoScVKgpYuXVrguMlkktlsLnScJAgAAAClGd1wrqVYSVBcXJzV+7y8PI0bN07btm1TTEyMWrRooYoVK+rcuXPatGmT5s2bp2bNmumFF14o0aABAAAA4HoVKwkKCQmxev/pp59q27ZtWrJkidVcrVq11KJFC3Xt2lU9evRQXFycBg8eXCIBAwAAAIA97NoY4auvvlL79u1tkqN81apVU/v27bVw4UJ7PgYAAABwam4mk1N+oWB2JUEJCQny9/e/5hp/f38lJCTY8zEAAAAAUGLsSoICAwO1YcOGQufNZrM2bNiggIAAez4GAAAAAEqMXUlQ+/bt9fvvv+upp57SyZMnreZOnjypp59+Wvv371eHDh3sChIAAABwZiaTc36hYMXaGOGvRo0apW3btmn16tVau3atgoKCVKFCBf35559KSkpSbm6uGjZsqJEjR5ZUvAAAAABgF7uSoHLlymn+/PmaPXu2lixZohMnTuj06dOSpOrVq6t79+6KjY2Vp6dniQQLAAAAAPayKwmSJE9PTw0bNkzDhg3T5cuXlZqaKl9fX5UrV64k4gMAAACcnoneM5didxJ0tXLlypH8AAAAAHBqdm2MAAAAAACupliVoDZt2shkMmnOnDmqVq2a2rRpU6TjTCaT1q5de10B3ixrn77X0SEAQIkKbM6mNABKl7c7THZ0CIWisuBaipUEmc1mmc1mq/dFPQ4AAAAAnEGxkqB169Zd8z0AAAAAOLsS3RgBAAAAMCJ2h3MttC8CAAAAMJRiVYKWLVt23R/UtWvX6z4WAAAAAEpKsZKgF154odilPrPZLJPJRBIEAACAUsuNbjiXUqwkaNy4cTcqDgAAAAC4KYqVBHXr1u1GxQEAAAAANwW7wwEAAAB2oh3OtbA7HAAAAABDsbsSlJaWpvnz52vDhg1KSkpSVlaWzRqTyaS1a9fa+1EAAAAAYDe7kqBLly6pX79+OnTokHx9fZWamio/Pz9lZ2crIyNDklS5cmW5u9N1BwAAgNKLh6W6Frva4aZNm6ZDhw7prbfe0pYtWyRJgwYN0vbt2/Xll1/qtttuU1hYmL777rsSCRYAAAAA7GVXErRu3To1b95cPXr0sMp+TSaTGjVqpBkzZujIkSOaNm2a3YECAAAAQEmwKwn6448/VL9+/f+dzM1N2dnZlvcVKlTQfffdp2+//daejwEAAACcmpvJOb9QMLuSIB8fH6sKkJ+fn86ePWu1pkKFCkpKSrLnYwAAAACgxNiVBAUHBysxMdHy/tZbb9XWrVuVl5dnGdu2bZsqVqxoz8cAAAAAQImxKwlq3ry5tmzZIrPZLEnq0KGDTpw4oaFDh+qLL77QqFGjtHPnTt1///0lEiwAAADgjEwm5/xCwezau7pbt27Kzs5WYmKiqlSpoocffli//vqr1q5dq40bN0qSmjRpoqeffrokYgUAAAAAu5nM+WWcErRnzx6dOHFCISEhatiwodzc7Co43RQZOY6OAABKVmDzkY4OAQBKVPr2yY4OoVDPf7Pf0SEU6N8dIxwdglO6IU8xbdCggRo0aHAjTg0AAAA4HTd6z1xKiZVo0tLStG/fPm3durWkTgkAAAAAJc7uJCgxMVFPPvmkWrRooR49emjgwIGWua1bt6pDhw7atGmTvR8DAAAAACXCriTozJkz6tWrl+Li4vTAAw+oUaNGuvoWo9tvv11//vknD0sFAABAqebmpF8omF3fm8mTJ+v8+fOaPXu2Jk+erLvvvttq3sPDQ82aNdNvv/1mV5AAAAAAUFLsSoL++9//qnXr1rrzzjsLXVOlShWdOXPGno8BAAAAgBJj1+5w586dU/Xq1a+5xsPDQ+np6fZ8DAAAAODU2BzOtdhVCQoICNAff/xxzTVHjx5VxYoV7fkYAAAAACgxdiVBTZo00bp163T27NkC548dO6YNGzbojjvusOdjAAAAAKDE2JUEPfLII8rKytKAAQO0fv16S9tbWlqa1q9fr2HDhslkMmnIkCElEiwAAADgjNxMJqf8QsHsuifo9ttv1+uvv67XXntNw4YNs4w3bdpUklSmTBm9/fbbqlOnjn1RAgAAAEAJsSsJkqSePXuqWbNmmj9/vnbu3Knk5GT5+vqqUaNG6t+/v2rVqlUScQIAAABAibA7CZKkGjVq6KWXXip0/vz58ypfvnxJfBQAAADgdEpj51lqaqrmzp2r77//XqdOnZKnp6dCQ0PVvXt39e7dWx4eHpa16enpmjJlir799ludOXNGlStXVseOHTV8+HD5+PjYnDshIUEffPCBNm7cqLS0NNWsWVMDBgxQr169bsq1lUgSVJiUlBTNmDFD8+bN44GpAAAAgIvIycnRoEGDtG/fPnXt2lX9+/dXVlaW1qxZozfeeEPbt2/X+PHjJUm5ubl67LHHtHnzZkVHR6t58+aKj4/XrFmztGvXLs2ZM0dubv/biiAxMVF9+vRRSkqKBg0apNDQUMXFxWns2LFKSkrSyJEjb/j1XXcSlJCQoL1798rd3V2RkZFW22BnZmbq008/1ezZs3Xx4sUCsz8AAAAAzmnz5s3as2ePhgwZon/84x+W8f79+6tHjx765ptv9Nprr8nX11dLly7V5s2bFRMTo7Fjx1rWhoSE6N1339WKFSvUtWtXy/gHH3ygs2fPatKkSYqKipIk9e7dW8OGDdO0adMUHR2tatWq3dDru67d4d588009+OCDeuqppzRixAi1bt1aX3zxhSRp06ZNat++vSZOnKj09HQNHDhQa9euLdGgAQAAAGfiZnLOr+uVkpIiSapcubLVeJkyZVSxYkWVKVNGnp6ekqTly5dLkmJjY63W9uvXT97e3lq2bJllLD09XatXr1ZoaKglAcoXGxurnJwcrVy58voDL6JiV4KWLl2qefPmyc3NTbfeeqsk6ciRI3rrrbdUtmxZvfLKK8rLy1OfPn30xBNPKCgoqMSDBgAAAPD32rRpc835uLi4AsebNGmismXLavr06QoKClKjRo2UmZmp7777Ths2bNCoUaPk6ekps9ms3bt3q3LlygoJCbE6h7e3t+rVq6fdu3dbxg4cOKCMjAw1atTI5jMbN24sk8mkXbt2Ff9Ci6nYSdCSJUvk4eGhzz77TI0bN5YkbdmyRbGxsfrnP/+p4OBgTZs2TRERESUeLAAAAIAbr1KlSpo6dapee+01PfPMM5ZxLy8vvfXWW+rRo4ckKTk5Wenp6YU+EicoKEjbt29XamqqfH19lZiYKEkKDg62Wevp6anAwEAlJSXdgCuyVuwk6MCBA3rwwQctCZAkNW/eXG3bttXq1av11ltvkQABAADAUJz1waSFVXqKwtfXVzVr1lSLFi109913KyMjQ0uXLtXLL78sk8mk7t27KyMjQ5IsrXF/5eXlJelKG5yvr6/S09P/dn3+mhup2ElQSkqKwsLCbMarV68uSVbJEQAAAADXEx8fr379+mnQoEEaM2aMZbxLly7q27ev3njjDT3wwAPy9vaWJGVlZRV4nszMTEmybJSW/+e11gcGBpbYdRSm2Bsj5OXlyd3dNnfK3yc8/xsBAAAAwDXNnTtXWVlZat++vdW4m5ub2rVrp/T0dO3atUsBAQHy8fGxtLn9VVJSknx9feXr6yvpf21wBa3PysrShQsXbsqeAte1O5zJSct9AAAAgCOYTM75db3OnDkj6UoB5K9ycnIsf5pMJjVo0EBnzpxRQkKC1bqMjAz9/vvvatiwoWUsPDxcXl5e2rFjh815d+zYIbPZrMjIyOsPvIiuKwmaPHmy6tWrZ/U1ZcoUSbIZr1evnm677bYSDRoAAADAjVO7dm1JVzZFu1p2drZWrVqlMmXKWJKb6OhoSdKcOXOs1i5YsEAZGRmWeelKO1xUVJROnTqlNWvWWK2fPXu23N3d1alTpxK/nr+6roelms3mG7oeAAAAgOMMGjRIy5cv14IFC5SYmKh7771X6enpWrFihfbv36/Y2FhL21r37t21bNkyff7550pJSVGzZs20f/9+zZ8/Xy1atFCXLl2szj169Gj98ssvev7557V3716FhoYqLi5OP/74o4YPH17g/gMlzWQmQ5EkZeQ4OgIAKFmBzUc6OgQAKFHp2yc7OoRCvRV3yNEhFOifbWpf97GnTp3S1KlT9fPPP+vs2bPy8PBQnTp11Lt3b/Xs2dPqFpnLly9rypQp+u6773T27FlVqlRJHTp00IgRI1S2bFmbc588eVITJkzQxo0blZaWpho1amjAgAHq06fPdcdbHCRB/48kCEBpQxIEoLQhCSo+e5Kg0uy67gkCAAAAAFd1XfcEAQAAAPgfk9g92ZVQCQIAAABgKCRBAAAAAAyFdjgAAADATm50w7kUKkEAAAAADIUkCAAAAICh0A4HAAAA2Il2ONdCJQgAAACAoZAEAQAAADAU2uEAAAAAO5lM9MO5EipBAAAAAAyFJAgAAACAodAOBwAAANiJ3eFcC5UgAAAAAIZCEgQAAADAUGiHAwAAAOzE5nCuhUoQAAAAAEMhCQIAAABgKLTDAQAAAHZyox/OpVAJAgAAAGAoJEEAAAAADIV2OAAAAMBOPCzVtVAJAgAAAGAoJEEAAAAADIV2OAAAAMBObA7nWqgEAQAAADAUkiAAAAAAhkI7HAAAAGAnN9EP50qoBAEAAAAwFJIgAAAAAIZCOxwAAABgJ3aHcy1UggAAAAAYCkkQAAAAAEOhHQ4AAACwkxvtcC6FShAAAAAAQyEJAgAAAGAotMMBAAAAdnJjeziXQiUIAAAAgKGQBAEAAAAwFNrhAAAAADvRDedaqAQBAAAAMBSSIAAAAACGQjscAAAAYCd2h3MtVIIAAAAAGApJEAAAAABDoR0OAAAAsBPdcK6FShAAAAAAQyEJAgAAAGAoJEEAAAAADIV7ggAAAAA7UVlwLfy8AAAAABgKSRAAAAAAQ6EdDgAAALCTiT2yXQqVIAAAAACGQhIEAAAAwFBohwMAAADsRDOca6ESBAAAAMBQSIIAAAAAGArtcAAAAICd3NgdzqVQCQIAAABgKCRBAAAAAAyFdjgAAADATjTDuRYqQQAAAAAMhSQIAAAAgKHQDgcAAADYic3hXAuVIAAAAACGQhIEAAAAwFBohwMAAADsZKIfzqVQCQIAAABgKCRBAAAAAAyFdjgAAADATlQWXAs/LwAAAACGQhIEAAAAwFBohwMAAADsxO5wroVKEAAAAABDoRIEAAAAoECpqamaMWOG1qxZo4SEBHl7e6t69eoaMGCAoqOjLevS09M1ZcoUffvttzpz5owqV66sjh07avjw4fLx8bE5b0JCgj744ANt3LhRaWlpqlmzpgYMGKBevXrdlOsiCQIAAADsVBqb4ZKSkjRw4EBduHBB3bp1U+3atZWenq5jx47p9OnTlnW5ubl67LHHtHnzZkVHR6t58+aKj4/XrFmztGvXLs2ZM0dubv9rQEtMTFSfPn2UkpKiQYMGKTQ0VHFxcRo7dqySkpI0cuTIG35tJEEAAAAAbDz//PO6fPmyli9fripVqhS6bunSpdq8ebNiYmI0duxYy3hISIjeffddrVixQl27drWMf/DBBzp79qwmTZqkqKgoSVLv3r01bNgwTZs2TdHR0apWrdoNuy6Je4IAAAAA/MW2bdv066+/6tFHH1WVKlWUm5ury5cvF7h2+fLlkqTY2Fir8X79+snb21vLli2zjKWnp2v16tUKDQ21JED5YmNjlZOTo5UrV5bsxRSAShAAAABgJ2fdHa5NmzbXnI+LiytwfP369ZKksLAwPfnkk/rxxx+VnZ2tSpUqqV+/fnr88cdVpkwZmc1m7d69W5UrV1ZISIjVOby9vVWvXj3t3r3bMnbgwAFlZGSoUaNGNp/ZuHFjmUwm7dq1q5hXWXxUggAAAABYOXz4sCTpn//8pxITE/Xmm2/q3XffVUhIiD788EO99tprkqTk5GSlp6crODi4wPMEBQUpNTVVqampkq7cDySpwPWenp4KDAxUUlLSDbgia1SCAAAAgFKqsErP38lvffPx8dEXX3whT09PSVKHDh3UsWNHff3114qNjbXs/JY//1deXl6SrrTB+fr6Kj09/W/X56+5kagEAQAAAHZyc9Kv6+Xt7S1J6ty5s1XC4unpqc6dO8tsNmvTpk2WdVlZWQWeJzMzU5IsyVL+n9daX9CW2iWNJAgAAACAlfx2tUqVKtnM5Y9dvHhRAQEB8vHxsbS5/VVSUpJ8fX3l6+trdd6C1mdlZenChQsKCgoqkWu4FpIgAAAAAFbyNy74448/bObyE5gKFSrIZDKpQYMGOnPmjBISEqzWZWRk6Pfff1fDhg0tY+Hh4fLy8tKOHTtszrtjxw6ZzWZFRkaW3IUUgiQIAAAAsJPJZHLKr+vVpk0b+fv7a/ny5ZZNDaQr9wotXbpUHh4euueeeyRJ0dHRkqQ5c+ZYnWPBggXKyMiwzEtX2uGioqJ06tQprVmzxmr97Nmz5e7urk6dOl133EXFxggAAAAArPj5+emf//yn/vGPf6hnz57q2bOnTCaTFi9erKSkJD3zzDOWB6h2795dy5Yt0+eff66UlBQ1a9ZM+/fv1/z589WiRQt16dLF6tyjR4/WL7/8oueff1579+5VaGio4uLi9OOPP2r48OEKCwu74ddnMpvN5hv+KS4gI8fREQBAyQpsPtLRIQBAiUrfPtnRIRRq6a6C74lxtG6RBW9dXVTr16/XjBkztHfvXuXl5Sk8PFyDBw9Wx44drdZdvnxZU6ZM0XfffaezZ8+qUqVK6tChg0aMGKGyZcvanPfkyZOaMGGCNm7cqLS0NNWoUUMDBgxQnz597Iq3qEiC/h9JEIDShiQIQGnjzEnQMidNgrramQSVVtwTBAAAAMBQSIIAAAAAGAobIwAAAAB2smMjNjgAlSAAAAAAhkISBAAAAMBQaIcDAAAA7OQm+uFcCZUgAAAAAIZCEgQAAADAUGiHAwAAAOzE7nCuhUoQAAAAAEMhCQIAAABgKLTDAQAAAHYysTucS6ESBAAAAMBQSIIAAAAAGArtcAAAAICd2B3OtVAJAgAAAGAoJEEAAAAADIV2OAAAAMBObuwO51KoBAEAAAAwFJIgAAAAAIZCOxwAAABgJ3aHcy1UggAAAAAYCkkQAAAAAEOhHQ4AAACwE+1wroVKEAAAAABDIQkCAAAAYCi0wwEAAAB2MvGwVJdCJQgAAACAoZAEAQAAADAU2uEAAAAAO7nRDedSqAQBAAAAMBSSIAAAAACG4pLtcFu2bFFycrJatmwpX19fR4cDAAAAg2N3ONfi1EnQJ598ok2bNmn27NmWsZEjRyouLk6SFBwcrC+//FJBQUGOChEAAACAi3HqdrjVq1erevXqlvc///yz1q5dq06dOunZZ59VcnKyZs2a5cAIAQAAALgap64EnT59Wt26dbO8X7t2rSpWrKh3331Xbm5uOnfunH788Ue99NJLDowSAAAARmeiG86lOHUlKC0tTWXLlrW837Ztm1q2bCk3tyth165dW2fOnHFUeAAAAABckFMnQZUqVdLRo0clSefOndOBAwfUrFkzy3xKSorc3Z26mAUAAADAyTh1BnHXXXdp/vz5CggI0KZNm+Tm5qb77rvPMn/06FEFBwc7MEIAAACA3eFcjVMnQSNHjtTWrVs1fvx4y/sqVapIknJycvTDDz+offv2jgwRAAAAgItx6iQoKChIq1at0qFDh+Tn56eqVata5jIyMvSvf/1LdevWdWCEAAAAAFyNUydBklSmTBlFRETYjPv6+qpt27YOiAgAAACw5kY3nEtx+iRIkn777TetWbNGJ06ckCSFhYUpKipKTZo0cXBkAAAAAFyN0ydBr7zyir7++muZzWar8blz56p37956/fXXHRQZAAAAAFfk1EnQF198oYULF+ruu+/WE088ofDwcEnSgQMHNG3aNC1cuFARERHq16+fgyMFAACAkbE7nGsxmf9aYnEiXbt2VdmyZTVv3jzLA1Lz5eXlqX///kpPT9eyZcvs/qyMHLtPAQBOJbD5SEeHAAAlKn37ZEeHUKifDlxwdAgFujc80NEhOCWnfljq0aNH1a5dO5sESJLc3NzUvn17y8NUAQAAAKAonLodzt3dXenp6YXOp6eny93dqS8BpVx2drZ+27ZVGzf8V1s3b9aJE8eVnp6uW24JUIOGDdWz98O67/4HCj0+Ly9Pq1Ys16qVy3Vgf7xSU1N1yy0Bqlmrlh6Maqc+ffvfvIsBUOrUqV5ZbVvWU+N61dS4Xpjq1gySu3sZvTZlpd6dubrAY4r6L+2PvPyZ5q/afM017e65TcsmDZckrdsUr47DinbuhuEh2jDvOXl6uOvwibNqEM39v3B+JrrhXIpTZxC33Xabvv76a/Xt21e33HKL1dylS5e0ePFi1a9f30HRAdK2rVv0+KOxkqSKFSupUZOm8vHx0ZHDh7X+Pz9q/X9+VI9effTyq6/L9JffjikpKXpq5BPatnWLfH19dXujxvLz89eZM0mKj/9dly+nkgQBsMtjve7VyP6tinXM5yt+LXSuWnCgHmgRoby8PG3YdvCa5wnw89HUl/spLy+vwI6Owni4l9HMf8XIvYxTN6sAcHFOnQQNHTpUjz/+uLp06aIBAwZYNkY4ePCgvvjiCyUlJemVV15xcJQwMpPJpLYPtlP/mIFq0rSZ1dz3332rl/4xRou//kqNGzdR5+iuljmz2aynnxyubVu3qGfvPnp2zD9Utlw5y3x2VpYOHNh/sy4DQCm19/BpTZi7VjvjT2l7/Ek9/0iU+ne645rHPPbqvELnJr7YWw+0iNC6Tft14o9r3//wwT96qXJ5P81YtEGP976vyDG/9NhDigwP1bQv1+uJh+8v8nEAUBxOnQTdd999euONNzRu3Di9//77ln9JN5vNKlu2rN544w3de++9Do4SRnbHnS11x50tC5xr/1AH/frLRi1dvEgrVyyzSoKWLV2srVs2666779HLr75hc6yHp6fqN2h4o8IGYBCfLv3F6n1e3vXvheTl6a7e7a/8Y8/cZb9cc22XVpHq27GFPvj0B/1+JFGP9y7aZzS9LUxjYh/U4jW/aenaHSRBcCl0w7kWp06CJKlXr1566KGHtGHDBp08eVLSlYel3n333fL19XVwdMC11a17myQpMfEPq/EF8z6XJA0e8uhNjwkArke3No0U6F9WfyZf1oofdxW6rkJAOX30z4e1/2ii3pj2jXq1a1qk83t5umvGv2J0ISVNz7yzUHVrVSmp0AHAhtMnQZLk6+ur9u3bOzoMoNhOHD8mSapUqbJl7M9z57R/f7zKlCmj2xs11qmTJ7X6++90+vQplS1bTg0jI9WqVRt5eHo6KGoAsDUw+krV+8tvNysru/DnSnz0Uh9VDPBV32dnKjOr6M+feHV4J9WrVUWDXpyjsxdSVdfuiAGgcC6RBAGu6NzZs1qxfKkkqc2DUZbx/Ht9bgkI0JLFX+v9f7+rnJxsq2NDq1XThA8nKzyCvwYAcLywKuV1f/M6kqRPr9EK16tdU3V/sIkmf/Gjftl5pMjnv/P2mho1oLVW/rhTC7/fZne8gCO4sT2cS3H6JGjXrl367LPPdOzYMSUnJ+uvz3Y1mUxau3atg6IDCpaTk6OXXnhOKSkpqhMerl69+ljmkpOTJUmXLl7Uu2+/qQej2unx4SMVUjVEhw4d1L/feVu7d+3U8Mcf1aJlKxUQwEPOADjWwOg75ebmpm17j2vPwdMFrgmq4KcJL/TW4RNn9crkFUU+t4+3h6a/HqOLqeka9fZXJRUyAFyTUydBK1eu1PPPP68yZcqoZs2aqlKF/mC4hjffeFWbfv1FAQEBGj/hI+vWtv9P5HNycnR7o8YaP+Ejy1Tk7Y30yczZ6vxQO509e1ZfLZivx58YcbPDBwALk8mkmC53SpLmLi+8CjT55X4K9PdR3zEzlZ6RXei6v3pzVLTqVK+sR17+TInnLtkdLwAUhVMnQdOmTVNYWJjmzp2r4OBgR4cDFMm7497U0sWL5O9/iz6eOUc1atS0mr96K+yeV1WI8pUr56uOnbvos09na9Ovv5AEAXCo1ndEKKxKeaWlZ+mr77YWuKZ/5zvU6f6G+mThf/XT3zw/6Gr3Nq2jYX3u03c/7fnbB68Czo5mONfi1EnQyZMnNWbMGBIguIzx/35H8+d9Lj9/f308Y5bq1bvNZk1oaLX/va5WzWb+yppQSdLZs2dvTKAAUESDul7ZEGFZ3A5dSs0ocE10q0hJUrP61bV6xlNWc0EV/CRJjeuFWeYGvjBbSX+mqEurSLm5ualacHmb427x85EkVa18i2XuufcWadeBhBK6MgBG5tRJUKVKlWzuAQKc1YTx/9bnc+fIz89PH0+fVehzfqrXqKFy5crp8uXLunCh4IcN5o+XLVv2hsULAH8n0L+sOj9wJcG51oYI+ZrWr37Nc93X7MrmCl6eHlZzDepULfQ4H29Py3G3+PE7EUDJcOokKDo6WqtXr9bgwYMdHQpwTRM/GK9P58y6kgDNmK0GDSMLXevu7q5Wbdpq1Yrl2vTLz2rT9kGbNb/+8rMkqUFDHpgKwHEe7tBc3l4eOnzi7DXb3HqPnlHo3IDOd2jGGzFatyleHYdNtpp7bvxiPTd+cYHH3du0jtbMfEqHT5xVg+jXr+8CgJuJfjiX4uboAK4lOjpaZrNZw4YN0y+//KKTJ0/q9OnTNl+AI03+cILmzJrx/y1w106A8j069HG5u3to8aKvtf4/P1rNfTp7prb/tk1lypTRw33736iwAeBvDYz++w0RAMAVOXUlqH379jKZTDKbzVq/fn2h637//febGBXwP/9ZF6cZ0z+WJIVVC9NXC+brqwXzbdYFBAbq2ef+YXlfs9atevX1f+nVl1/SqBHDVL9+A1UNubJF9tEjR1SmTBn98+XXVCc84qZdC4DSp1HdUH344v82YKlZraIk6dEe96jDvQ0s432enWGzM9vtEaFqVLeacnJyNW/lppsTMADcJE6dBI0YMUImHjwFJ3bx4kXL671792jv3j0FrqtaNcQqCZKkLl27qdatt2rOrJn67bet2r9/vwICAhTVrr0GDn5EDSP/vqIEANfiV85HLSJr2oyHBgcqNPh/zyDz9LD960D+hgg//PK7/jh70WYegDUT/XAuxWRm5wFJUkaOoyMAgJIV2Hyko0MAgBKVvn3y3y9ykE2HnfMfC+649RZHh+CUnPqeIAAAAAAoaU7dDpcvNzdXR48eVXJycoFbZjdv3twBUQEAAABXcAeHa3H6JGjWrFn65JNPlJKSUugaNkYAAAAAUFRO3Q63ZMkSvffeewoPD9fTTz8ts9msQYMGaciQIfL391fDhg319ttvOzpMAAAAAC7EqZOg+fPnq2HDhpo3b5569+4tSbr//vv13HPPacWKFTpx4oSDIwQAAACuPCvVGb9QMKdOgg4fPqyHHnpIkixbZefl5UmSgoKC1KdPH3322WcOiw8AAACA63HqJEiS/Pz8JEk+Pj6SrJ/LEhoaqqNHjzokLgAAAACuyamToKCgICUkJEiSvLy8VKlSJe3Z87+HUR46dEi+vr6OCg8AAAC4wtF9b/TDFYtT7w7XpEkT/fzzz3r66aclSW3atNHnn3+usmXLKi8vTwsWLNCDDz7o2CABAAAAuBSnToIefvhhrV27VhkZGfL29tZTTz2lXbt2afLkK08LrlOnjp577jkHRwkAAADAlZjMBT191Mnt379fZcqUUa1ateTmVjIdfRk5JXIaAHAagc1HOjoEAChR6dsnOzqEQm09esnRIRSoWU1/R4fglJy6EvRXJ0+e1DfffKOkpCTVrl1boaGh8vb2dnRYAAAAQKmXl5enhx9+WDt37lTLli316aefWs2np6drypQp+vbbb3XmzBlVrlxZHTt21PDhwy2bnF0tISFBH3zwgTZu3Ki0tDTVrFlTAwYMUK9evW74tThdErRo0SJ99tlnmjNnjipUqGAZ37hxo0aOHKmMjAyZzWaZTCYtXLhQCxYsUNmyZR0YMQAAAFD6zZ07VwcPHixwLjc3V4899pg2b96s6OhoNW/eXPHx8Zo1a5Z27dqlOXPmWHVwJSYmqk+fPkpJSdGgQYMUGhqquLg4jR07VklJSRo58sZ2MzhdEvSf//xH5cqVs0qAzGazXn31VWVkZGjo0KFq3Lix1qxZo6VLl+qzzz7TsGHDHBgxAAAAjM5UyndiO3nypD788EM988wzevvtt23mly5dqs2bNysmJkZjx461jIeEhOjdd9/VihUr1LVrV8v4Bx98oLNnz2rSpEmKioqSJPXu3VvDhg3TtGnTFB0drWrVqt2w63G6LbLj4+PVtGlTq7Ht27fr1KlT6tSpk0aPHq1WrVpp3Lhxat68udauXeugSAEAAABjGDt2rGrXrq2YmJgC55cvXy5Jio2NtRrv16+fvL29tWzZMstYenq6Vq9erdDQUEsClC82NlY5OTlauXJlyV7AXzhdEnT+/HmbrO+3336TyWTSQw89ZDX+wAMP6NixYzcxOgAAAMBYFi5cqK1bt+rNN98scFMys9ms3bt3q3LlygoJCbGa8/b2Vr169bR7927L2IEDB5SRkaFGjRrZnKtx48YymUzatWtXiV/H1ZyuHc5kMik7O9tqLP+b8NdvVGBgoDIyMm5WaAAAAECBnLUbrk2bNtecj4uLu+Z8UlKS/v3vfys2NlZ169YtcE1ycrLS09NVp06dAueDgoK0fft2paamytfXV4mJiZKk4OBgm7Wenp4KDAxUUlLSNeOyl9NVgqpWrart27db3ufm5mrbtm0KDQ1V+fLlrdZeunRJAQEBNzlCAAAAwBhee+01BQYGXnOjgvyihKenZ4HzXl5ekq60wV3957XW56+5UZyuEnT//ffr008/VePGjXXnnXdq8eLFOn/+vDp27Gizds+ePTYlNwAAAABX/F2l51q++eYbrVu3TnPmzLnmY2ny57Kysgqcz8zMlCTLNtn5f15rfWBg4HXHXRROlwQNGTJES5cu1VtvvSXpSo+hv7+/zU1WGRkZ+s9//qOHH37YEWECAAAA/+Os/XDXKSsrS2+++abuuecehYSE6Pjx41bzGRkZOn78uGVXZx8fH0ub218lJSXJ19dXvr6+kv7XBlfQ+qysLF24cEG33357CV+RNadLgsqXL69FixZp5syZOn78uMLCwhQbG6sqVapYrdu1a5fuuOMOmx0lAAAAANgnIyND58+f14YNGwr8+/b27dsVFRWlDh06aMKECWrQoIG2bNmihIQEq06tjIwM/f7772rcuLFlLDw8XF5eXtqxY4fNeXfs2CGz2azIyMgbcl35nC4JkqQqVaro5ZdfvuaaFi1aqEWLFjcpIgAAAMA4fHx89OGHHxY499RTTyk8PFwjRoywFCqio6O1ZcsWzZkzx+o5QQsWLFBGRoaio6Otzh0VFaWVK1dqzZo1VknW7Nmz5e7urk6dOt2gK7vCKZMgAAAAwJWYSlk/nIeHh9q3b1/ofIUKFazmu3fvrmXLlunzzz9XSkqKmjVrpv3792v+/Plq0aKFunTpYnX86NGj9csvv+j555/X3r17FRoaqri4OP34448aPny4wsLCbti1SSRBAAAAAOxUpkwZTZ8+XVOmTNF3332nb775RpUqVVJsbKxGjBihMmXKWK2vWrWqvvzyS02YMEFffvml0tLSVKNGDb3xxhvq06fPDY/XZDabzTf8U1xARo6jIwCAkhXYvPDtTAHAFaVvn+zoEAq1/XiKo0MoUOPqfo4OwSlRCQIAAADsZCpd3XClntM9LBUAAAAAbiSSIAAAAACGQjscAAAAYCe64VwLlSAAAAAAhkISBAAAAMBQaIcDAAAA7EU/nEuhEgQAAADAUEiCAAAAABgK7XAAAACAnUz0w7kUKkEAAAAADIUkCAAAAICh0A4HAAAA2MlEN5xLoRIEAAAAwFBIggAAAAAYCu1wAAAAgJ3ohnMtVIIAAAAAGApJEAAAAABDoR0OAAAAsBf9cC6FShAAAAAAQyEJAgAAAGAotMMBAAAAdjLRD+dSqAQBAAAAMBSSIAAAAACGQjscAAAAYCcT3XAuhUoQAAAAAEMhCQIAAABgKLTDAQAAAHaiG861UAkCAAAAYCgkQQAAAAAMhXY4AAAAwF70w7kUKkEAAAAADIUkCAAAAICh0A4HAAAA2MlEP5xLoRIEAAAAwFBIggAAAAAYCu1wAAAAgJ1MdMO5FCpBAAAAAAyFJAgAAACAodAOBwAAANiJbjjXQiUIAAAAgKGQBAEAAAAwFNrhAAAAAHvRD+dSqAQBAAAAMBSSIAAAAACGQjscAAAAYCcT/XAuhUoQAAAAAEMhCQIAAABgKLTDAQAAAHYy0Q3nUqgEAQAAADAUkiAAAAAAhkI7HAAAAGAnuuFcC5UgAAAAAIZCEgQAAADAUGiHAwAAAOxFP5xLoRIEAAAAwFBIggAAAAAYCu1wAAAAgJ1M9MO5FCpBAAAAAAyFJAgAAACAodAOBwAAANjJRDecS6ESBAAAAMBQSIIAAAAAGArtcAAAAICd6IZzLVSCAAAAABgKSRAAAAAAQ6EdDgAAALAX/XAuhUoQAAAAAEMhCQIAAABgKLTDAQAAAHYy0Q/nUqgEAQAAADAUkiAAAAAAhkI7HAAAAGAnE91wLoVKEAAAAABDIQkCAAAAYCi0wwEAAAB2ohvOtZAEAQAAALBx7NgxrVy5Uhs3btTJkyd1+fJlVa1aVXfddZcee+wxVa5c2Wp9Tk6OZs+ercWLFyshIUEBAQFq06aNnn76aQUGBtqc/8KFC5o4caLi4uKUnJyskJAQ9ezZU7GxsXJ3v7FpCkkQAAAAABuLFi3SF198oVatWumhhx6St7e3duzYofnz52vFihVasGCBbr31Vsv6F198UStWrFCrVq30yCOP6NSpU5o7d65+++03ffXVVypbtqxlbWpqqgYMGKCjR4+qX79+ioiI0JYtWzR+/HgdOXJE48aNu6HXRhIEAAAA2Kk07g7Xrl07PfbYY/L397eM9enTR40aNdIrr7yijz76SB9++KEk6ZdfftGKFSvUunVrTZs2zbK+fv36GjVqlGbPnq2RI0daxmfNmqVDhw7phRdeUGxsrCSpV69e8vPz07x589S9e3c1b978hl0bGyMAAAAAsNGwYUOrBChfx44dJUn79++3jC1fvlySLAlNvnbt2ikkJMQyf/V6Hx8f9e3b12o8//hly5bZHf+1UAkCAAAASqk2bdpccz4uLq7Y50xKSpIkVaxY0TK2c+dOubm5qVGjRjbrGzdurFWrVik5OVkBAQE6d+6cEhIS1LhxY3l7e1utDQ0NVaVKlbRr165ix1UcVIIAAAAAu5mc9Kvk5bfAde/e3TKWmJiowMBAeXp62qwPCgqyrLn6z+Dg4ALPHxwcbEm0bhQqQQAAAEApdT2Vnmv5+OOPtXr1arVt21bdunWzjGdkZOiWW24p8BgvLy/Lmqv/LChhyl+fnp5ekmHboBIEAAAA4G/NnTtXEyZMUIsWLTR+/HiZrtoNwtvbW1lZWQUel5mZaVlz9Z/XWu/j41OSodugEgQAAADYqTTuDne1OXPm6J133lHLli01bdo0myQlODhYx44dU1ZWlk2FJ7+1Lb/9Lf/P/La4v0pMTLS00N0oVIIAAAAAFGr69Ol65513dO+99+qTTz4psEoTGRmpvLw87dy502Zu+/btCgsLU0BAgKQrGypUrVpV8fHxlta4fAkJCTp79qwiIyNvyLXkIwkCAAAAUKCPP/5Y77//vlq1aqWpU6da7u/5q+joaEnS7NmzrcbXrFmjhIQEy3y+Ll26KD09XQsWLLAanzNnjtX5bhTa4QAAAAA7lcZuuC+++EITJkxQxYoV9eCDD+q7776zmi9Xrpzatm0rSbrrrrvUqVMnrVq1SsOGDVObNm106tQpffrpp6pdu7bN84OGDh2q1atX67333lNCQoIiIiK0ZcsWLV++XNHR0WrRosUNvTaT2Ww239BPcBEZOY6OAABKVmDzkX+/CABcSPr2yY4OoVCnkwu+yd/RqgYUvANbUbzwwgtaunRpofMhISFat26d5X12drZmz56tJUuWKCEhQQEBAWrdurWefvpplS9f3ub48+fPa+LEiVq3bp2Sk5MVEhKiHj16aMiQIXJ3v7G1GpKg/0cSBKC0IQkCUNqQBBWfPUlQaUY7HAAAAGCn0r47XGnDxggAAAAADIUkCAAAAICh0A4HAAAA2MlUKveHK72oBAEAAAAwFJIgAAAAAIZCOxwAAABgL7rhXAqVIAAAAACGQhIEAAAAwFBohwMAAADsRDeca6ESBAAAAMBQSIIAAAAAGArtcAAAAICdTPTDuRQqQQAAAAAMhSQIAAAAgKHQDgcAAADYycT+cC6FShAAAAAAQyEJAgAAAGAotMMBAAAA9qIbzqVQCQIAAABgKCRBAAAAAAyFdjgAAADATnTDuRYqQQAAAAAMhSQIAAAAgKHQDgcAAADYyUQ/nEuhEgQAAADAUEiCAAAAABgK7XAAAACAnUzsD+dSqAQBAAAAMBSSIAAAAACGQjscAAAAYCd2h3MtVIIAAAAAGApJEAAAAABDIQkCAAAAYCgkQQAAAAAMhSQIAAAAgKGwOxwAAABgJ3aHcy1UggAAAAAYCkkQAAAAAEOhHQ4AAACwk0n0w7kSKkEAAAAADIUkCAAAAICh0A4HAAAA2Ind4VwLlSAAAAAAhkISBAAAAMBQaIcDAAAA7EQ3nGuhEgQAAADAUEiCAAAAABgK7XAAAACAveiHcylUggAAAAAYCkkQAAAAAEOhHQ4AAACwk4l+OJdCJQgAAACAoZAEAQAAADAU2uEAAAAAO5nohnMpVIIAAAAAGApJEAAAAABDoR0OAAAAsBPdcK6FShAAAAAAQyEJAgAAAGAotMMBAAAA9qIfzqVQCQIAAABgKCRBAAAAAAyFdjgAAADATib64VwKlSAAAAAAhkISBAAAAMBQaIcDAAAA7GSiG86lUAkCAAAAYCgkQQAAAAAMxWQ2m82ODgIAAAAAbhYqQQAAAAAMhSQIAAAAgKGQBAEAAAAwFJIgAAAAAIZCEgQAAADAUEiCAAAAABgKSRAAAAAAQyEJAgAAAGAoJEEAAAAADIUkCAAAAIChkAQBAAAAMBSSIAAAAACGQhIEAAAAwFBIggAn0Lp1a8XExBRp7alTpxQREaFJkyaVeBybNm1SRESElixZUuLnBgAAcBbujg4AKEnp6en64osvtHr1ah09elSZmZmqXLmy7rzzTg0ZMkS33nqro0MEgJvmzz//1Jw5c7R+/XolJCTIbDarfPnyqlu3rh544AH16tXL0SECgEOQBKHUOHnypB599FEdO3ZM999/vzp16qSyZcvq4MGDWrp0qZYvX67XX39dPXr0cHSoNr7//ntHhwCglDl9+rR69eqlCxcuqF27durVq5c8PDx08uRJ/fbbb/rss89IggAYFkkQSoXMzEwNGzZMJ06c0IQJE9ShQwer+UcffVSDBw/W2LFjFRoaqjvuuMNBkRbM09PT0SEAKGVmzZqlc+fO6aWXXtKgQYNs5s+ePeuAqADAOZAEoVRYtGiRDh06pIEDB9okQJJUuXJlvf/+++ratavee+89LVq0yDIXERGhbt26qWvXrpo4caLi4+Pl5eWlVq1a6bnnnlOFChUsa1NTUzVz5kz9/PPPOnHihFJTU1W5cmU98MADGjVqlAICAmw+Oy4uTp9//rn27t2rjIwMS3ves88+q/Lly0u6ck9QSEiIPv/8c6tjV61apenTp+vo0aMKCAhQhw4dCvyX27y8PE2fPl0bN27U0aNHlZycrMDAQN1111166qmnVLVqVZtjPvvsM33xxRdKSEhQ5cqV1aNHDzVu3LjI33MAzu3YsWOSpJYtWxY4X6lSJcvrXbt2acGCBfrtt9+UlJQkSbr11lvVr18/m+r5pEmTNHnyZH3//fdasWKFli1bprNnz6patWp64okn1KVLF5vP+u9//6sZM2Zo7969ysnJUc2aNdW7d2/169dPJpPJsi4xMVFTpkzRxo0bdfbsWZUtW1YhISGKiorSsGHD7P2WAIAFSRBKhfx2sr59+xa6pl69emrcuLG2b9+u06dPWyUG+/bt0+rVq9W9e3d16dJFu3fv1tKlS7Vz504tWrRI5cqVkyQlJSVp4cKFevDBB9WhQwd5enpq9+7d+uqrr7Rt2zYtWrRIHh4elvN++OGHmjp1qsLCwjRgwAAFBwfr9OnT+vHHH5WUlGRJggqyYMECvfbaa6pRo4ZGjBghDw8PrVy5Ulu2bLFZm52drRkzZigqKkr333+//Pz8tH//fi1evFi//PKLVqxYYZWgjR8/XjNmzFD9+vU1evRoZWVladGiRYqLiyvy9xyAcwsLC5MkLVmyRGPGjJG7e+H/yf/hhx908OBBtW/fXlWrVlVKSoq+++47vfTSSzp//ryGDh1qc8wLL7wgk8mkmJgYubm5af78+XruuecUFhamRo0aWdZ9/fXXevnll1W1alU98sgjKleunL7//nu98cYbio+P17/+9S9JUk5OjmJjY5WYmKiHH35YtWrVUlpamo4cOaJff/2VJAhAyTIDpUCLFi3MjRs3/tt1b7zxhjk8PNy8bt06y1h4eLg5PDzc/N1331mtnTNnjjk8PNz80UcfWcYyMzPNWVlZNudduHChOTw83Pztt99axnbu3GkODw839+7d23z58mWbY3Jzcy2vW7VqZR4wYIDl/aVLl8yNGjUyP/DAA+ZLly5ZxtPT083R0dE2ceXl5ZnT0tJsPmPjxo3m8PBw84wZMyxjx44dM9etW9fcs2dPc2ZmpmX8woUL5rvvvtscHh5uXrx4sc25ALiWEydOmJs2bWoODw83t2zZ0vzkk0+ap0+fbt66davV7x+z2Vzo76h+/fqZmzZtavV776OPPjKHh4ebH330UavznD592ly/fn3z6NGjLWP5v8vuvvtu859//mkZz87ONsfGxprDw8PNW7ZsMZvNZvPvv/9uDg8PN3/yyScl9j0AgMKwRTZKhdTUVPn5+f3tOl9fX0lSSkqK1XiNGjXUvn17q7F+/frJ399fa9assYx5enpaKj05OTm6dOmSzp8/rzvvvFPSlZaSfCtXrpQkjR49WmXLlrWJxc2t8P/7bdiwQWlpaerfv7/VdXl7e2vIkCE2600mk3x8fCRdaY3Lj6tu3bry8/OziuuHH35QXl6ehgwZYnUvUkBAgPr3719oTABcS7Vq1bR8+XLFxMTIx8dHq1ev1vjx49WvXz89+OCD2rBhg2Xt1b+jMjIydOHCBSUnJ+vee+9VSkqKjh49anP+wYMHW/0eq1KlimrWrGm1Nv93WUxMjFXl293dXU888YQkWX7H5v+u27RpE/crAbjhaIdDqeDr66vU1NS/XZe/5q8JU+3atW3Wenp6qlq1ajp06JDV+MKFCzV//nwdPHhQOTk5VnPJycmW1/n9+PXr1y/KJVg5efJkoXHVqVOnwGPWrl2rmTNnas+ePcrOzi40rhMnThT73ABcU0hIiMaOHauxY8fqzz//1Pbt2/Xdd9/pm2++0ciRI7V8+XJVr15d58+f10cffaS1a9cWmIBcvHjRZqxatWo2YwEBAUpISLC8z/9dFh4ebrM2fyz/d1JISIhGjhypqVOn6t5771V4eLiaNm2qtm3b6u67776+bwAAFIIkCKVCeHi4Nm/erKNHj6pmzZqFrtu7d6+kK5shXI+5c+fq7bff1l133aVXX31VlStXlqenp3JycjR06FCZzebrOq+91q5dqxEjRqhBgwZ68cUXVaVKFXl7e0uSnnnmGYfFBcB5VKhQQW3btlXbtm1VtWpVTZ8+Xd98842eeOIJPfroozpw4IAGDBighg0byt/fX2XKlNH69ev16aefKi8vz+Z816pmX68nn3xS3bt313//+19t3bpVa9as0fz589WmTRtNmTLFahMFALAHSRBKhXbt2mnz5s368ssv9eKLLxa4Jj4+Xtu3b1fDhg1tdkv7a7VHkrKysnTy5ElVr17dMrZs2TKFhIRo1qxZVn8BOHz4sM3xNWrU0H//+1/t27dPLVq0KNb15P8L66FDh/TAAw9YzR08eNBm/bJly+Tl5aV58+ZZ2uIkKS0tTZcuXbJam3+z9KFDh2wqPwWdG0Dpk78TZFJSkvbv36+9e/dq+PDheuqpp6zWbdy40a7Pyf99c/DgQbVq1cpqLv/3Tf6afCEhIerbt6/69u2rnJwcvfDCC1q5cqU2b97sdI83AOC6uCcIpULPnj1Vq1Ytff7551q9erXN/Llz5zRmzBi5ublpzJgxNvPHjh2zeWDp/PnzdenSJT344IOWsfzE5+p/FTWbzZoyZYrNOTt37ixJ+uCDD5SRkWEzf63qzD333KOyZcvqiy++sLp/KTMzU7Nnz7ZZ7+bmJpPJZPOvtVOnTrUZa9u2rUwmk2bPnq2srCzLeHJysr744otCYwLgWjZt2qT09PQC53744QdJV9piy5QpI8n2d1JSUpLV4wSux9133235XXZ1S11ubq6mTZsmSYqKipJ05V7Nv7byuru7q27dupKs23oBwF5UglAqeHt76+OPP9bQoUM1atQotWrVSnfffbe8vb116NAhLV26VJcvX9a//vUvyyYGVwsPD9eLL76orVu3qlatWpYtsmvUqGG1EUH79u01fvx4PfLII2rXrp0yMjL0ww8/2PyHW5IiIyM1bNgwffzxx+rSpYs6deqkKlWqKDExUXFxcRo3bpzq1atX4PX4+flpzJgxeuONN9SzZ091795dHh4eWrFiRYEtKO3bt9fq1asVExOjbt26yWw2a8OGDTp06JACAwOt1taoUUOxsbGaPXu2Hn74YXXq1EnZ2dn6+uuvVblyZW5IBkqJuXPnatOmTXrggQfUoEED+fv768KFC1q/fr02b96s8PBw9ejRQ15eXgoPD9fMmTOVlpamOnXq6NSpU/ryyy9VrVo1u5IPPz8/vfTSS3r55ZfVo0cP9ejRw7JJw2+//abevXurWbNmkq4kbWPHjtWDDz6omjVrys/PT4cPH9aXX36poKAg3XXXXSX0nQEAkiCUItWrV9fSpUv1xRdfaM2aNZo4caIyMzNVuXJltW3bVkOGDClwMwDpyuYF//znPzVx4kR9/fXX8vLyUpcuXfT8889bdpSTpEceeUTSlYezjhs3TgEBAWrTpo2eeeaZAlvennnmGd122236/PPP9emnnyonJ0eVK1dWy5YtFRwcfM3ryd8ZbsaMGZo0aZICAgLUsWNH9erVSx07drRa26FDB6WlpWnu3Ll67733VK5cOd11112aP3+++vXrZ3Pu559/XkFBQZo/f74++OADq4elxsbG/u33GoDze/zxx1WjRg1t2bJFv/76q5KTk+Xl5aUaNWpo1KhRGjRokGVXuE8++UTjx4/XqlWrlJqaqpo1a+q5556Tm5tboS3GRdWrVy9VrlxZM2fO1PTp0y0PS3355ZetdqSMiIhQu3bttHXrVn377bfKyclRUFCQevbsqUcffbRIO4ACQFGZzNwxDYOLiIhQt27d9M477zg6FAAAANwE3BMEAAAAwFBIggAAAAAYCkkQAAAAAEPhniAAAAAAhkIlCAAAAIChkAQBAAAAMBSSIAAAAACGQhIEAAAAwFBIggAAN8SGDRtUr149vfzyy44OBQAAKyRBAOBCIiIiFBMTYzU2adIkRUREaNOmTQ6L4a8SEhL07LPPqk2bNnrttdduSlwAABSVu6MDAABnExERYfXezc1N/v7+ioiIUK9evdS5c2cHReYasrKyNGrUKIWHh+v9999XmTJlHB0SAABWSIIAoBAjR46UJOXk5OjIkSOKi4vTpk2btGfPHr344osOju5/+vfvrw4dOqhq1ao35fO+/fZb+fj4FDofHx+v1q1ba+DAgfLy8ropMQEAUBw8LBUA/iK/ErR//36r8V9++UWxsbGSpLVr1yo0NNQhsbVo0UKff/75Tf9sAABKC+4JAoAiatmypWrVqiWz2azdu3dLsr4fZ+XKlerVq5caN26s1q1bW45LT0/XJ598oujoaDVq1EiNGzdWnz59tGrVqgI/JysrS1OmTFHbtm3VoEEDtW7dWhMmTFBWVlaB6691T9Dhw4f14osvqnXr1mrQoIFatmypfv36af78+de9trB7glJSUvT++++rXbt2atiwoZo3b65HHnlEP//8s83aTZs2KSIiQpMmTdLvv/+uxx57TM2aNdPtt9+uAQMG6LfffivwWgEAKAm0wwFAMeQXz00mk9X4nDlztHHjRrVq1Up33HGHUlJSJEmXLl3SoEGDtG/fPtWvX189evRQXl6eNmzYoGeffVYHDx7UM888Y3X+p59+WnFxcQoLC9OAAQOUnZ2txYsX68CBA8WK9T//+Y+eeuopZWVl6d5771XHjh116dIl7d+/XzNnzlS/fv2ua21BLl26pL59++rQoUNq2LChBg0apAsXLui7777TkCFD9Nprr+nhhx+2OW7Pnj2aOXOmGjVqpF69eun06dNas2aNBg8erGXLlqlWrVrFumYAAIqCJAgAiujnn3/W0aNHZTKZ1LBhQ6u5X3/9VV999ZVuu+02q/G3335b+/bt05gxYzR06FDLeGZmpoYPH65PPvlE7du3V7169SRJq1atUlxcnBo1aqTPPvvMck/Nk08+qZ49exY51vPnz+vZZ59Vbm6u5s6dqxYtWljNJyYmXtfawowfP16HDh1Snz599Prrr1uSxKFDh6pHjx568803dc8999i0EP7nP//RuHHj1L17d8vYl19+qVdffVWfffYZO8sBAG4I2uEAoBCTJk3SpEmTNGHCBI0aNUqPPvqozGazBg0apJCQEKu1vXv3tkmALly4oBUrVqhBgwZWCZAkeXl56bnnnpPZbNbKlSst40uWLJEkPfPMM1abCgQEBGj48OFFjn3ZsmVKTU3Vww8/bJPUSFJwcPB1rS1IVlaWVqxYobJly2r06NFWVbIaNWooJiZG2dnZWrZsmc2xTZo0sUqAJKlHjx5yd3fXrl27/u4yAQC4LlSCAKAQkydPlnSl9c3f319NmzZVz549FR0dbbM2MjLSZmz37t3Kzc2VyWTSpEmTbOZzcnIkSUeOHLGM7du3T25ubmratKnN+oISlMLs2LFDknTfffeV6NqCHD16VOnp6WrSpIkCAgJs5u+8805NmzZNv//+u81cgwYNbMY8PDxUoUIFXbp06briAQDg75AEAUAh/ro73LVUrFjRZiw5OVnSlWQofyOFgly+fNnyOiUlRbfccos8PDxs1lWqVKnI8eTfkxQUFFSia691fGHx5Y8XlNT4+/sXeIy7u7vy8vKuKx4AAP4OSRAAlIC/bpQgSX5+fpKkwYMHF/m5Qn5+frp48aKys7NtEqGzZ88WOZ78z05KSrJ5+Ks9a691/Llz5wqcz487fx0AAI7GPUEAcINERkbKzc1NW7duLfIxt912m/Ly8rRt2zabuc2bNxf5PI0aNZIk/fe//y3RtQWpWbOmfHx8FB8fX2C1J3/r7r/eMwUAgKOQBAHADVKhQgV17txZe/bs0ZQpU5Sbm2uz5sSJEzp58qTlff4mARMnTlRmZqZlPDk5WdOmTSvyZ3ft2lW+vr768ssvtWXLFpv5q3d8K87agnh6eqpz5876v/bu2OW0OI7j+MegDJIkm5TFxGBRkpT1bHaLwaAsJgP/AcWGwcBCSUkSZZPFZjIYWJTZGZR67nTV7T739txbeobf+7Web53O2d71+/W1bVutVuuXZ5fLRYPBQE6n89O7VAAAfAeOwwHAG9XrdZ3PZ7Xbbc1mM8Xjcfn9ft1uN51OJx0OBzWbTQWDQUmSZVlaLBbabDayLEvZbFbP51PL5VLRaFSXy+VL7/X5fGo0GiqXy8rn80qn04pEIrrf7zoej7per9psNv88+yeVSkX7/V7D4VCHw0GJROK1J8i2bdVqtdc3AgDw3YggAHgjt9utwWCg8Xis+Xyu1Wqlx+Mhv9+vUCikarWqZDL5mnc4HGq1Wup2u5pOpxoOhwoEAsrlciqVSr/tJ/qbTCajyWSiXq+n3W6n7XYrj8ejcDisYrH437Of8Xq9Go1G6nQ6Wq/X6vf7crlcisViKhQKSqVSX/9pAAC8mePj5/pzAAAAADAAd4IAAAAAGIUIAgAAAGAUIggAAACAUYggAAAAAEYhggAAAAAYhQgCAAAAYBQiCAAAAIBRiCAAAAAARiGCAAAAABiFCAIAAABgFCIIAAAAgFGIIAAAAABG+QH97S+0Su8DKwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "VP = aciertosO\n",
    "FP = fallosO\n",
    "FN = fallosS\n",
    "VN = aciertosS\n",
    "\n",
    "# Crear la matriz de confusiÃ³n\n",
    "matriz_confusion = [[VP, FP],\n",
    "                    [FN, VN]]\n",
    "\n",
    "# Etiquetas para las clases\n",
    "clases = ['Opacidad', 'Sanos']\n",
    "\n",
    "# ConfiguraciÃ³n del heatmap con Seaborn\n",
    "sns.set(font_scale=1.2)  # Ajusta el tamaÃ±o de la fuente\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Crear el heatmap con etiquetas personalizadas\n",
    "sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\", annot_kws={\"size\": 16},xticklabels=clases, yticklabels=clases)\n",
    "\n",
    "# ConfiguraciÃ³n adicional\n",
    "plt.xlabel('PredicciÃ³n')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.savefig('/home/jair/COVID/YOLO8/runs/detect/train/'+mode+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab03f2b-a95d-4a19-94f9-bd732c406c8a",
   "metadata": {},
   "source": [
    "<h3>Generar conteos para matrices de confusiÃ³n para Siim y Xray14</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dd93a-ab63-4b76-9460-6fb32ed6b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conjunto de generaciÃ³n test o validacion\n",
    "mode='test'\n",
    "\n",
    "n=4 #4 SIIM 8 Xray14\n",
    "\n",
    "# Define las etiquetas de las clases\n",
    "if n==4:\n",
    "    #Typical Appearance, Negative for Pneumonia, Indeterminate Appearance,Atypical Appearance\n",
    "    etiquetas_clases = ['TÃ­pico', 'Negativo', 'Indeterminado', 'AtÃ­pico']\n",
    "if n==9:\n",
    "    #Atelectasis,Effusion,Cardiomegaly,Infiltrate,No Finding,Pneumonia,Pneumothorax,Mass,Nodule\n",
    "    etiquetas_clases = ['Atelectasia', 'EfusiÃ³n','Cardiomegalia','InfiltrasiÃ³n', 'Sin Hallazgo','NeumonÃ­a','NeumotÃ³rax','Masa','Nodule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898b096-2044-4201-b551-cf15a177ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Supongamos que tienes los conteos en un array de n elementos\n",
    "conteos = [10, 2, 3, 1,\n",
    "           0, 20, 1, 3,\n",
    "           5, 2, 15, 8,\n",
    "           2, 6, 9, 20]\n",
    "\n",
    "# Organiza los conteos en una matriz de 4x4 o 9x9\n",
    "matriz_confusion = np.array(conteos).reshape((n,n))\n",
    "\n",
    "\n",
    "# Crea el mapa de calor utilizando Seaborn\n",
    "sns.set(font_scale=1.2)  # Ajusta el tamaÃ±o de la fuente\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(matriz_confusion, annot=True, cmap='Blues', fmt='d', xticklabels=etiquetas_clases, yticklabels=etiquetas_clases)\n",
    "plt.xlabel('Clase Predicha')\n",
    "plt.ylabel('Clase Verdadera')\n",
    "plt.title('Matriz de ConfusiÃ³n')\n",
    "plt.savefig('/home/jair/COVID/YOLO8/runs/detect/train/'+mode+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca81b2d-dbfc-47b7-b04c-f26674d53e8e",
   "metadata": {},
   "source": [
    "<h1>Visualizando anotaciones originales para imagen especifica<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b75e4c-e81f-4d00-99b2-41b753731cb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 40 (2066867510.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 42\u001b[0;36m\u001b[0m\n\u001b[0;31m    data_img= data.loc[data['id'] == imagen_name.replace('.png','')]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 40\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from ultralytics import YOLO\n",
    "import panadas as pd\n",
    "from ast import literal_eval\n",
    "import os\n",
    "\n",
    "\n",
    "def yolon_to_xywh(bb,scale):\n",
    "    x=bb[0]*scale-bb[2]*scale/2\n",
    "    y=bb[1]*scale-bb[3]*scale/2\n",
    "    wp=bb[2]*scale\n",
    "    hp=bb[3]*scale\n",
    "    return [x, y, wp, hp]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#conjunto utilizado\n",
    "conj='RSNAS' #RSNAS,RSNAI,RSNAC,Xray14,SIIM\n",
    "\n",
    "#imagen que queremos predecir\n",
    "imagen_name='dc3f50d6-3e8c-4c5b-814b-3f2043165556.png'\n",
    "\n",
    "#abrimos imagen\n",
    "imagen = Image.open(rt+imagen_name)\n",
    "\n",
    "# Convierte la imagen a un arreglo NumPy\n",
    "imagen_array = np.array(imagen)\n",
    "\n",
    "#tamaÃ±o de imagen (cuadrada)\n",
    "scale=640\n",
    "\n",
    "bboxes=[]\n",
    "#para RSNA con imagenes que tienen etiquetas de solo opacidad\n",
    "if conj=='RSNAS':\n",
    "    rl='/home/jair/COVID/rsna/datasets/opacity_labels_yolo/labels/test/'\n",
    "    #raiz donde estan las imagens de prueba\n",
    "    rt='/home/jair/COVID/rsna/datasets/rsna640opacity/images/test/'\n",
    "    \n",
    "#para RSNA con imagenes con etiquetas de opacidad y pulmon individual\n",
    "if conj=='RSNAI':\n",
    "    rl='/home/jair/COVID/rsna/datasets/comb_labels_yolo/pulmones_individuales/labels/test/'\n",
    "    #raiz donde estan las imagens de prueba\n",
    "    rt='/home/jair/COVID/rsna/datasets/rsna640opacity/images/test/'\n",
    "\n",
    "#para RSNA con imagenes con etiquetas de opacidad e imagen completa\n",
    "if conj=='RSNAC':\n",
    "    rl='/home/jair/COVID/rsna/datasets/comb_labels_yolo/imagen_completa/labels/test/'\n",
    "    #raiz donde estan las imagens de prueba\n",
    "    rt='/home/jair/COVID/rsna/datasets/rsna640opacity/images/test/'\n",
    "\n",
    "#para Xray14 con imagenes con etiquetas de opacidad e imagen completa\n",
    "if conj=='Xray14':\n",
    "    rl='/home/jair/COVID/NIHX14/datasets/yolo/640/labels/test/'\n",
    "    #raiz donde estan las imagens de prueba\n",
    "    rt='/home/jair/COVID/NIHX14/datasets/yolo/640/images/test/'\n",
    "    \n",
    "#para SIIMCOVID con imagenes con etiquetas de opacidad e imagen completa\n",
    "if conj=='SIIM':\n",
    "    rl='/home/jair/COVID/siimcovid/datasets/yolo/labels/test/'\n",
    "    #raiz donde estan las imagens de prueba\n",
    "    rt='/home/jair/COVID/siimcovid/datasets/yolo/images/test/'\n",
    "\n",
    "anotation=rl+imagen_name.replace('png','txt')\n",
    "if os.path.exists(anotation):\n",
    "    with open(anotation, 'r') as archivo_txt:\n",
    "        for linea in archivo_txt:\n",
    "            partes = linea.split()\n",
    "            valores = [float(valor) for valor in partes[1:]]\n",
    "            bboxes.append(valores)          \n",
    "                \n",
    "#muestra anotaciones de la imagen    \n",
    "fig, ax= plt.subplots(1, 1, figsize=(8, 8), facecolor='w', edgecolor='b')\n",
    "\n",
    "if len(bboxes)>0:\n",
    "    for bb in bboxes:\n",
    "        #convierte bbox de formato yolo a xywh\n",
    "        bbp=yolon_to_xywh(bb,scale)\n",
    "        #dibuja recuadros\n",
    "        patch = ax.add_patch(patches.Rectangle((bbp[0],bbp[1]),bbp[2],bbp[3],fill=False,edgecolor='red',lw=2))\n",
    "        \n",
    "ax.imshow(imagen_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a56468-d4e7-404e-9e54-e228ab58f06c",
   "metadata": {},
   "source": [
    "<h1>Visualizando predicciones del modelo para la imagen.</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734219c3-880a-4872-b959-359323c73a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta de pesos del modelo entrenado\n",
    "model_path='/home/jair/entrenamientos/n/train/weights'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "imagen_path=rt+imagen_name\n",
    "\n",
    "#lista de predicicones\n",
    "results = model(imagen_path)  \n",
    "\n",
    "\n",
    "# Mostrando resultados\n",
    "for r in results:\n",
    "    print(r.boxes.cls)\n",
    "    im_array = r.plot() \n",
    "    im = Image.fromarray(im_array[..., ::-1]) \n",
    "    im.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
